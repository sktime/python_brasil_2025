[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Previsão de Séries temporais com Python: um pequeno guia",
    "section": "",
    "text": "Prefácio\nEsse é um pequeno livro feito para o workshop de sktime na Python Brasil 2025. O objetivo é apresentar os conceitos básicos de séries temporais e como usar o sktime para modelagem e previsão.\nEsse livro é raso em diversos aspectos, mas pode ser útil como ponto de partida para quem quer aprender mais sobre séries temporais em Python.\nCaso queira contribuir para sktime, visite o repositório oficial no GitHub e participe do nosso Discord.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "content/pt/part1/index.html",
    "href": "content/pt/part1/index.html",
    "title": "1  Definição do problema",
    "section": "",
    "text": "Em modelos de regressão e classificação básicos, supomos que os dados são i.i.d: variaveis aleatórias independentes e identicamente distribuidas. Ou seja, a ordem que observamos os dados não tem nenhum impacto em nossa habilidade de prever quais serão as próximas observações.\nVamos considerar um experimento simples: temos uma caixa com bolas pretas e vermelhas dentro. Digamos que as bolas pretas valem 1 e as bolas vermelhas valem 0. Queremos descobrir qual a quantidade de pontos vamos ter na próxima rodada.\n\n\n\nBolas pretas e vermelhas\n\n\nSe as bolas estão distribuidas aleatóriamente dentro da caixa, podemos esperar ver algo como a seguinte sequência de pontos:\n\\[\n\\{0, 1, 1, 0, 1, 0, 0, \\dots \\}\n\\]\nNesse caso, a ordem dos pontos não importa. Não importa o que vimos até então; a próxima bola que vamos tirar da caixa é independente das bolas que já tiramos.\nVamos supor um caso ligeiramente diferente. Agora, as bolas estão organizadas em blocos: primeiro todas as bolas pretas, depois todas as bolas vermelhas, depois todas as bolas pretas de novo, e assim por diante. Nesse caso, podemos esperar ver algo como:\n\\[\n\\{1, 1, 1, 0, 0, 0, 1, 1, 1, \\dots \\}\n\\]\nNesse caso, a ordem dos pontos importa. Se vimos muitas bolas pretas recentemente, é mais provável que vejamos uma bola preta na próxima rodada. A próxima bola que vamos tirar da caixa depende das bolas que já tiramos. Esse é um caso básico de aplicação de modelos de previsão de séries temporais.\nConsiderando que cada observação é indexada por uma variável temporal, podemos definir uma série temporal como uma sequência de observações ordenadas no tempo. Exemplos comuns de séries temporais incluem:\n\nVarejo: vendas diárias, semanais ou mensais de um produto\nFinanças: preços diários de ações, taxas de câmbio\nSaúde: número diário de novos casos de uma doença\nClima: temperatura diária, precipitação mensal\n\nEsse livro é uma introdução prática a modelos de séries temporais, com objetivo de dar contexto das ferramentas mais relevantes em 3h de leitura.\nO conteúdo está organizado nas seguintes seções:\n\nIntrodução a séries temporais:\n\nModelo Naive, Modelo Naive sazonal\nSéries integradas, diferenciação e estacionariedade\nModelo de Suavização Exponencial (Exponential Smoothing)\nModelos autoregressivos (AR)\nMétricas de avaliação de modelos de séries temporais\nEngenharia de features para séries temporais\n\nModelos avançados e caso de uso\n\nForecast com modelos de Machine Learning\nForecast com modelos fundacionais\nPrevisão de vendas totais agregadas\nPrevisão de vendas por região e modelos globais\nPrevisão hierárquica e reconciliação\n\nCustomização de modelos com sktime\n\nComo customizar e criar modelos em sktime\nCriando um wrapper de biblioteca externa",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definição do problema</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/naive.html",
    "href": "content/pt/part1/naive.html",
    "title": "2  Primeiro passos com sktime e modelo Naive",
    "section": "",
    "text": "2.1 Exemplo prático com sktime\nConsiderando o nosso exemplo da caixa com bolas pretas e vermelhas, um modelo simples para prever a próxima bola que vamos tirar da caixa é o Modelo Naive.\nExistem algumas versões de modelo naive:\nEsse modelo é simples, mas é extremamente eficaz e dificil de ser vencido em muitos casos. No cenário onde os dados não vêm organizados em nenhuma ordem específica, a melhor aposta que podemos fazer é o valor médio das bolas no histórico recente.\nVamos ver como fazer um forecast simples com sktime, usando o modelo Naive.\nAqui, baixamos o dataset simples que vem na biblioteca desse repositório.\nfrom tsbook.datasets.simple import SimpleDataset\n\n\ndataset = SimpleDataset(True)\ny = dataset.load(\"y\")\n\ny.head()\n\n\n\n\n\n\n\n\npoints\n\n\n\n\n2021-01-01\n0\n\n\n2021-01-02\n0\n\n\n2021-01-03\n0\n\n\n2021-01-04\n1\n\n\n2021-01-05\n1\nEsse é um dataset simples com uma série temporal mensal. Vamos dividir os dados em treino e teste, usando os últimos 36 meses como teste. Para isso, devemos respeitar a ordem temporal dos dados.\nA função temporal_train_test_split faz isso para nós.\nfrom sktime.forecasting.model_selection import temporal_train_test_split\ny_train, y_test = temporal_train_test_split(y, test_size=36)\nTambém temos uma função de plotagem simples para visualizar séries temporais.\nfrom sktime.utils.plotting import plot_series\n\nplot_series(y, labels=[\"Observações\"])",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Primeiro passos com sktime e modelo Naive</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/naive.html#exemplo-prático-com-sktime",
    "href": "content/pt/part1/naive.html#exemplo-prático-com-sktime",
    "title": "2  Primeiro passos com sktime e modelo Naive",
    "section": "",
    "text": "2.1.1 Criando o modelo\nNo sktime, os modelos são usados em 3 passos:\n\nInicialização (__init__): aqui, definimos os hiperparâmetros do modelo. Pense nessa parte como a configuração do modelo.\nTreinamento (fit): aqui, o modelo aprende com os dados de treino.\nPrevisão (predict): com esse método, o modelo faz previsões para os dados futuros.\n\nQuando inicializamos o modelo em um notebook, o sktime mostra uma ilustração do modelo, o que é útil para entender o que está acontecendo “por baixo dos panos”. Em casos mais complexos com composição de modelos, isso pode ser útil para ilustrar o que estamos fazendo para outros cientistas.\n\nfrom sktime.forecasting.naive import NaiveForecaster\n\nmodel = NaiveForecaster(strategy=\"last\")\nmodel\n\nNaiveForecaster()Please rerun this cell to show the HTML repr or trust the notebook.NaiveForecaster?Documentation for NaiveForecasterNaiveForecaster()\n\n\nAo treinar o modelo, passamos dados de treinamento.\n\nmodel.fit(y_train)\n\nNaiveForecaster()Please rerun this cell to show the HTML repr or trust the notebook.NaiveForecaster?Documentation for NaiveForecasterNaiveForecaster()\n\n\nPara a previsão, temos que passar um argumento obrigatório: fh, abreviatura de “forecasting horizon” (horizonte de previsão). Tipicamente passamos um fh relativo, ou seja, no formato de uma lista\n\nmodel.predict(fh=[1,2,3,4])\n\n\n\n\n\n\n\n\npoints\n\n\n\n\n2021-03-06\n1.0\n\n\n2021-03-07\n1.0\n\n\n2021-03-08\n1.0\n\n\n2021-03-09\n1.0\n\n\n\n\n\n\n\nOnde cada número representa o número de períodos à frente que queremos prever. Também podemos passar o fh como um índice de tempo absoluto, que é o que faremos aqui. Vamos passar o índice de tempo do conjunto de teste.\n\ny_pred = model.predict(fh=y_test.index)\n\nplot_series(y_train, y_test, y_pred, labels=[\"Treino\", \"Teste\", \"Previsão\"])\n\n\n\n\n\n\n\n\n\n\n2.1.2 Ajustando hiperparâmetros\nPara alterar hiperparametros de um modelo já existente, podemos usar o método set_params, que modifica in-place os hiperparâmetros do modelo.\n\nmodel.set_params(\n    strategy=\"mean\",\n    window_length=12,\n)\n\nmodel.fit(y_train)\ny_pred = model.predict(fh=y_test.index)\n\n\nplot_series(y_train, y_test, y_pred, labels=[\"Treino\", \"Teste\", \"Previsão\"])\n\n\n\n\n\n\n\n\nPodemos também testar o Naive sazonal, que repete a última observação de 6 períodos atrás.\n\nmodel.set_params(\n    sp=6,\n    strategy=\"last\"\n\n)\nmodel.fit(y_train)\ny_pred = model.predict(fh=y_test.index)\nplot_series(y_train, y_test, y_pred, labels=[\"Treino\", \"Teste\", \"Previsão\"])\n\n\n\n\n\n\n\n\nClaro, como esse exemplo é muito simples, o modelo naive sazonal captura perfeitamente a sazonalidade dos dados. No entanto, vamos ver no próximo capítulo um caso de uso mais realista, com dados de varejo, e estudaremos modelos mais avançados.",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Primeiro passos com sktime e modelo Naive</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/components_and_diff.html",
    "href": "content/pt/part1/components_and_diff.html",
    "title": "3  Decomposição de séries temporais e modelos clássicos",
    "section": "",
    "text": "3.1 Importando dados\nNesse capítulo, vamos começar a usar um dataset mais realista, com dados simulando vendas diárias de uma empresa de varejo.\nVamos aprender os seguintes pontos:\nPara acessar os dados, vamos usar a classe SyntheticRetail da biblioteca tsbook, que contém dados simulados de vendas diárias de uma empresa de varejo.\nfrom tsbook.datasets.retail import SyntheticRetail\nfrom sktime.utils.plotting import plot_series\n\ndataset = SyntheticRetail(\"univariate\")\ny_train, y_test = dataset.load(\"y_train\", \"y_test\")\n\nplot_series(y_train, y_test, labels=[\"Treino\", \"Teste\"])\nOs dados são diários, e vemos que sempre positivos. Também notamos que existe alguma sazonalidade, aparentemente algo mensal e anual, que aumenta de magnitude ao longo do tempo.\nAlgo que deve chamar a atenção nesse gráfico é que a magnitude da série temporal está aumentando ao longo do tempo. Isso não deve passar desapercebido, pois é um ponto importante para entendermos o que vem a seguir.",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais e modelos clássicos</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/components_and_diff.html#auto-correlação",
    "href": "content/pt/part1/components_and_diff.html#auto-correlação",
    "title": "3  Decomposição de séries temporais e modelos clássicos",
    "section": "3.2 Auto-correlação",
    "text": "3.2 Auto-correlação\nÉ interessante entender o quanto de informação o passado de uma série temporal carrega sobre o seu futuro. Uma maneira de capturar essa relação (considerando variações lineares) é através da auto-correlação. A autocorrelação para um determinado lag \\(k\\) é definida como:\n\\[\n\\text{Corr}(Y_t,Y_{t-k})=\\frac{\\text{Cov}(Y_t,Y_{t-k})}{\\sqrt{\\text{Var}(Y_t)\\text{Var}(Y_{t-k})}} = \\frac{E[(Y_t - \\mu)(Y_{t-k} - \\mu)]}{\\sqrt{\\text{Var}(Y_t)\\text{Var}(Y_{t-k})}}\n\\]\nEm outras palavras, quando o valor em \\(k\\) observações atrás está acima (ou abaixo) da média, o valor atual também tende a estar acima (ou abaixo) da média?\nCom plot_correlations, podemos visualizar algumas informações úteis:\n\nNo plot superior, vemos a série temporal original.\nNo canto inferior esquerdo, temos o gráfico de autocorrelação (ACF), que mostra a correlação entre a série temporal e suas versões defasadas (lags). Valores próximos de 1 ou -1 indicam uma forte correlação positiva ou negativa, respectivamente.\nNo canto inferior direito, temos o gráfico de autocorrelação parcial (PACF), que mostra a correlação entre a série temporal e suas versões defasadas, controlando para as correlações intermediárias. É útil para entender o efeito isolado de um lag.\n\n\nfrom sktime.utils.plotting import plot_correlations\n\n\nfig, ax = plot_correlations(y_train, lags=60)\nfig.show()\n\n\n\n\n\n\n\n\nNo gráfico de autocorrelação, vemos algumas características interessantes:\n\nValores são extremamente altos, e decaem lentamente ao longo do tempo.\nExistem oscilações claras, indicando padrões sazonais na série temporal.\n\n\n\n\n\n\n\nTip\n\n\n\nÉ um erro comum usar a correlação de lags de uma série para seleção de variáveis (lags). Sempre que possível, devemos eliminar a tendência antes de analisar a autocorrelação.\n\n\nVeremos que esses padrões são indicativos de que a série temporal possui componentes importantes, e que valores passados dizem muito sobre valores futuros.",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais e modelos clássicos</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/components_and_diff.html#componentes-de-séries-temporais",
    "href": "content/pt/part1/components_and_diff.html#componentes-de-séries-temporais",
    "title": "3  Decomposição de séries temporais e modelos clássicos",
    "section": "3.3 Componentes de séries temporais",
    "text": "3.3 Componentes de séries temporais\nSéries temporais podem ser decompostas em 3 componentes principais:\n\nTendência: padrão de longo prazo na série temporal\nSazonalidade: padrões que se repetem em intervalos regulares, como diariamente, semanalmente ou anualmente\nRuído: variação aleatória que não pode ser explicada pelos outros componentes\n\nUma série aditiva pode ser representada como:\n\\[\nY(t) = T(t) + S(t) + R(t)\n\\]\nonde \\(T(t)\\) é a tendência, \\(S(t)\\) é a sazonalidade, e \\(R(t)\\) é o ruído.\nEm séries aditivas, o impacto da sazonalidade se dá em termos absolutos, dizemos: “em janeiro, as vendas aumentam em 100 unidades com relação a média do ano”.\nMas também existem séries multiplicativas, onde os componentes interagem de forma diferente:\n\\[\nY(t) = T(t) \\cdot S(t) \\cdot R(t)\n\\]\nNessas séries, o impacto da sazonalidade se dá em termos relativos, dizemos: “em janeiro, as vendas aumentam em 20% com relação a média do ano”. Esse é o caso mais comum para séries não-negativas, como vendas. Isso vem por definição: se temos vendas muito baixas, por exemplo, 10 unidades, não faz sentido dizer que em janeiro as vendas diminuem em 100 unidades, pois isso levaria a vendas negativas. Já dizer que as vendas diminuem em 20% é perfeitamente razoável.\n\n\n\n\n\n\nTip\n\n\n\nEm alguns casos, as séries multiplicativas são definidas como:\n\\[\nY(t) = T(t) + T(t) \\cdot S(t) + T(t) \\cdot R(t)\n\\]\n\n\nQuando a série é multiplicativa, podemos fazer recurso ao logaritmo para transformá-la em aditiva:\n\\[\nlog(Y(t)) = log(T(t)) + log(S(t)) + log(R(t))\n\\]\nPara fazer isso no sktime, usamos o transformador LogTransformer. Transformadores são usados para pré-processar ou pós-processar os dados antes de aplicar um modelo de previsão, e sua interface é similar a dos modelos de previsão:\n\n__init__: define os hiperparâmetros do transformador\nfit: aprende os parâmetros do transformador a partir dos dados\ntransform: aplica a transformação nos dados\ninverse_transform (opcional): aplica a transformação inversa nos dados\n\n\nfrom sktime.transformations.series.boxcox import LogTransformer\nlog_transformer = LogTransformer()\nlog_transformer.fit(y_train)\n\nLogTransformer()Please rerun this cell to show the HTML repr or trust the notebook.LogTransformer?Documentation for LogTransformerLogTransformer()\n\n\n\ny_train_log = log_transformer.transform(y_train)\nplot_series(y_train_log, labels=[\"Logaritmo\"])\n\n\n\n\n\n\n\n\nAinda que não esteja perfeito, essa transformação estabiliza as variações da série temporal, o que é importante para alguns modelos de previsão.\n\n3.3.1 Decompondo a série temporal\nSktime fornece algumas opções para decompor séries temporais. Aqui, vamos usar o Detrender para remover a tendência, e o Deseasonalizer para remover a sazonalidade.\n\n3.3.1.1 Tendência\n\nfrom sktime.transformations.series.detrend import Detrender, Deseasonalizer\n\n\ndetrender = LogTransformer() * Detrender(model=\"additive\")\ndetrender.fit(y_train)\ny_train_detrended = detrender.transform(y_train)\nplot_series(y_train_detrended, labels=[\"Detrended\"])\n\n\n\n\n\n\n\n\nVemos uma mudança importante no gráfico de autocorrelação:\n\nfig, _ = plot_correlations(y_train_detrended, lags=60)\nfig.show()\n\n\n\n\n\n\n\n\nO que indica que, ao eliminar a tendencia, a informação que o passado carrega sobre o futuro diminuiu bastante. Na verdade, a existência da tendência - um efeito de longo prazo - faz com que valores passados sejam altamente correlacionados com valores futuros, e pode dar a falsa impressão de que a série é “fácil” de modelar.\n\n\n3.3.1.2 Sazonalidade\nAgora, usamos o Deseasonalizer para remover a sazonalidade:\n\ndeseasonalizer = LogTransformer() * Deseasonalizer(model=\"additive\", sp=365)\ndeseasonalizer.fit(y_train)\ny_train_deseasonalized = deseasonalizer.transform(y_train)\nplot_series(y_train_log, y_train_deseasonalized, labels=[\"Log with seasonality\", \"Deseasonalized\"])\n\n\n\n\n\n\n\n\nPodemos usar o Detrender e o Deseasonalizer juntos para remover ambos os componentes:\n\nremove_components = LogTransformer() * Detrender(model=\"additive\") * Deseasonalizer(model=\"additive\", sp=365) \nremove_components.fit(y_train)\ny_train_removed = remove_components.transform(y_train)\nplot_series(y_train_log, y_train_removed, labels=[\"Log with seasonality\", \"Deseasonalized and detrended\"])\n\n\n\n\n\n\n\n\n\nfig, _ = plot_correlations(y_train_removed, lags=60)\nfig.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTente adicionar mais um deseasonalizer para remover a sazonalidade semanal.",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais e modelos clássicos</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/components_and_diff.html#séries-estacionárias",
    "href": "content/pt/part1/components_and_diff.html#séries-estacionárias",
    "title": "3  Decomposição de séries temporais e modelos clássicos",
    "section": "3.4 Séries estacionárias",
    "text": "3.4 Séries estacionárias\nO conceito de estacionariedade é fundamental em séries temporais. Uma série temporal é dita estacionária se suas propriedades estatísticas, como média, variância e autocovariância, são constantes ao longo do tempo, não importando a janela e quando ela é observada.\n\nMais precisamente, se \\(Y(t)\\), onde \\(t\\) é o indice temporal, então dizemos que ela é estacionária se:\n\\[\nP(Y(t_{start}:t_{end})) = P(Y(t_{start}+k:t_{end}+k)), \\quad \\forall k, t_{start}, t_{end} \\in \\mathbb{Z}\n\\]\n\nClaramente, a série temporal que estamos analisando não é estacionária. Basta percebermos que para valores maiores de \\(t\\), a média e a variância são maiores.\nO aumento da média da série ao longo do tempo é chamado de tendência. A tendência é um padrão de longo prazo na série temporal, e um grande desafio para previsões de longo prazo.\nExistem definições mais “suaves” de estacionariedade, como a estacionariedade fraca, que requer apenas que propriedades como média e autovariância sejam constantes ao longo do tempo.\nNo fundo, o que nos interessa mais é ter uma série temporal que seja “fácil”de modelar. Para alguns algoritmos, como Naive, é importante que ela seja o mais próxima possível de estacionária. Veja abaixo o problema geraodo quando aplicamos o modelo Naive diretamente na série temporal original.\n\nfrom sktime.forecasting.naive import NaiveForecaster\n\nnaive = NaiveForecaster(strategy=\"mean\", window_length=24)\nnaive.fit(y_train)\ny_pred = naive.predict(fh=y_test.index)\n\nplot_series(y_train, y_test, y_pred, labels=[\"Treino\", \"Teste\", \"Previsão Naive\"])\n\n\n\n\n\n\n\n\n\n3.4.1 Diferenciação\nUma técnica simples e eficaz para lidar com séries não estacionárias é a diferenciação. Calculamos:\n\\[\nY'(t) = Y(t) - Y(t-1)\n\\]\ne fazemos previsões em \\(Y'(t)\\) ao invés de \\(Y(t)\\). Para obter a previsão de \\(Y(t)\\), precisamos fazer o processo inverso: somar a previsão de \\(Y'(t)\\) com o valor anterior de \\(Y(t-1)\\).\n\\[\n\\hat{Y(t)} = \\hat{Y'}(t) + \\hat{Y}(t-1), \\quad \\hat{Y}(0) \\text{ conhecido}\n\\]\nCom sktime, isso é extremamente fácil. Aqui, vamos usar um transformador chamado Differencer.\n\nfrom sktime.transformations.series.difference import Differencer\ndiff = Differencer()\ndiff.fit(y_train)\n\nDifferencer()Please rerun this cell to show the HTML repr or trust the notebook.Differencer?Documentation for DifferencerDifferencer()\n\n\n\ny_train_diff = diff.transform(y_train)\n\nplot_series(y_train, y_train_diff, labels=[\"Original\", \"Diferenciado\"])",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais e modelos clássicos</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/components_and_diff.html#criando-um-pipeline-com-diferenciação-e-naive",
    "href": "content/pt/part1/components_and_diff.html#criando-um-pipeline-com-diferenciação-e-naive",
    "title": "3  Decomposição de séries temporais e modelos clássicos",
    "section": "3.5 Criando um pipeline com diferenciação e Naive",
    "text": "3.5 Criando um pipeline com diferenciação e Naive\nAgora, podemos criar um modelo de forecasting mais complexo, composto por dois passos:\n\nDiferenciação dos dados\nModelo Naive aplicado nos dados diferenciados\n\nPara isso, usamos a classe TransformedTargetForecaster, que cria um pipeline de transformadores e um modelo de previsão.\n\nfrom sktime.forecasting.compose import TransformedTargetForecaster\n\nmodel = TransformedTargetForecaster(steps=[\n    (\"differencer\", Differencer()),\n    (\"naive\", NaiveForecaster(strategy=\"mean\", window_length=24))\n])\nmodel.fit(y_train)\n\nTransformedTargetForecaster(steps=[('differencer', Differencer()),\n                                   ('naive',\n                                    NaiveForecaster(strategy='mean',\n                                                    window_length=24))])Please rerun this cell to show the HTML repr or trust the notebook.TransformedTargetForecaster?Documentation for TransformedTargetForecasterTransformedTargetForecaster(steps=[('differencer', Differencer()),\n                                   ('naive',\n                                    NaiveForecaster(strategy='mean',\n                                                    window_length=24))])Differencer?Documentation for DifferencerDifferencer()NaiveForecaster?Documentation for NaiveForecasterNaiveForecaster(strategy='mean', window_length=24)\n\n\nOu apenas:\n\nmodel = Differencer() * NaiveForecaster(strategy=\"mean\", window_length=24)\nmodel.fit(y_train)\n\nTransformedTargetForecaster(steps=[Differencer(),\n                                   NaiveForecaster(strategy='mean',\n                                                   window_length=24)])Please rerun this cell to show the HTML repr or trust the notebook.TransformedTargetForecaster?Documentation for TransformedTargetForecasterTransformedTargetForecaster(steps=[Differencer(),\n                                   NaiveForecaster(strategy='mean',\n                                                   window_length=24)])Differencer?Documentation for DifferencerDifferencer()NaiveForecaster?Documentation for NaiveForecasterNaiveForecaster(strategy='mean', window_length=24)\n\n\nE agora podemos prever:\n\ny_pred = model.predict(fh=y_test.index)\nplot_series(y_train, y_test, y_pred, labels=[\"Treino\", \"Teste\", \"Previsão Naive com diferenciação\"])\n\n\n\n\n\n\n\n\nExistem ainda alguns problemas com a diferenciação. Note que a variância da série temporal diferenciada não é constante ao longo do tempo. Aqui, podemos combinar nossa transformação logarítmica com a diferenciação.\nPrimeiro, vamos criar um transformador que combina as duas transformações:\n\nfrom sktime.transformations.compose import TransformerPipeline\n\nlog_diff = TransformerPipeline(steps=[\n    (\"log\", LogTransformer()),\n    (\"diff\", Differencer())\n])\nlog_diff.fit(y_train)\n\nTransformerPipeline(steps=[('log', LogTransformer()), ('diff', Differencer())])Please rerun this cell to show the HTML repr or trust the notebook.TransformerPipeline?Documentation for TransformerPipelineTransformerPipeline(steps=[('log', LogTransformer()), ('diff', Differencer())])LogTransformer?Documentation for LogTransformerLogTransformer()Differencer?Documentation for DifferencerDifferencer()\n\n\n\ny_train_log_diff = log_diff.transform(y_train)\nplot_series(y_train_log_diff, labels=[\"Log + Diferenciado\"])\n\n\n\n\n\n\n\n\nPara fazer forecast, criamos um pipeline com o transformador combinado e o modelo Naive:\n\nmodel = log_diff * NaiveForecaster(strategy=\"mean\", window_length=24)\nmodel.fit(y_train)\ny_pred = model.predict(fh=y_test.index)\nplot_series(y_train, y_test, y_pred, labels=[\"Treino\", \"Teste\", \"Previsão Naive com log + diferenciação\"])",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais e modelos clássicos</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/ets_and_ar.html",
    "href": "content/pt/part1/ets_and_ar.html",
    "title": "4  Modelos estatísticos clássicos e diferenciação",
    "section": "",
    "text": "4.1 Exponential Smoothing\nO Modelo Naive, que calculada a média dos últimos valores, é um modelo muito simples, mas que pode ser melhorado. Analizando o que ele faz:\n\\[\n\\hat{Y}(t) = \\frac{Y(t-1) + Y(t-2) + \\dots + Y(t-n)}{n}\n\\]\nEle basicamente atribui o mesmo peso para todas as observações passadas. Mas, intuitivamente, faz mais sentido dar mais peso para as observações mais recentes, e menos peso para as observações mais antigas.\nO exponential smoothing faz exatamente isso. Ele atribui pesos decrescentes para observações mais antigas. O peso da observação decresce exponencialmente segundo um fator \\(0 &lt; \\alpha &lt; 1\\) (Hyndman and Athanasopoulos 2018):\n\\[\n\\hat{Y}(t) = \\alpha Y(t-1) + \\alpha(1 - \\alpha)Y(t-1) + \\alpha(1 - \\alpha)^2 Y(t-2) + \\dots\n\\]\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 4))\nalpha = 0.3\nweights = [alpha * (1 - alpha) ** i for i in range(20)]\nax.bar(range(len(weights)), weights)\nax.set_title(\"Pesos do Exponential Smoothing\")\nax.set_xlabel(\"Observações passadas\")\nax.set_ylabel(\"Peso\")\nplt.show()",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelos estatísticos clássicos e diferenciação</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/ets_and_ar.html#exponential-smoothing",
    "href": "content/pt/part1/ets_and_ar.html#exponential-smoothing",
    "title": "4  Modelos estatísticos clássicos e diferenciação",
    "section": "",
    "text": "4.1.1 Usando Exponential Smoothing com sktime\n\nfrom tsbook.datasets.retail import SyntheticRetail\nfrom sktime.utils.plotting import plot_series\n\ndataset = SyntheticRetail(\"univariate\")\ny_train, y_test = dataset.load(\"y_train\", \"y_test\")\n\n\nfrom sktime.utils.plotting import plot_series\nfrom sktime.forecasting.exp_smoothing import ExponentialSmoothing\n\nmodel = ExponentialSmoothing()\nmodel.fit(y_train)\n\nExponentialSmoothing()Please rerun this cell to show the HTML repr or trust the notebook.ExponentialSmoothing?Documentation for ExponentialSmoothingExponentialSmoothing()\n\n\n\ny_pred = model.predict(fh=y_test.index)\nplot_series(y_train, y_test, y_pred, labels=[\"Treino\", \"Teste\", \"Previsão Exponential Smoothing\"])\n\n\n\n\n\n\n\n\nExistem versões alternativas que consideram sazonalidade e tendências. Veja a documentação para mais detalhes.\n\nmodel = ExponentialSmoothing(trend=\"add\", seasonal=\"add\", sp=7)\nmodel.fit(y_train)\ny_pred = model.predict(fh=y_test.index)\nplot_series(\n    y_train,\n    y_test,\n    y_pred,\n    labels=[\"Treino\", \"Teste\", \"Previsão Exponential Smoothing\"],\n)",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelos estatísticos clássicos e diferenciação</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/ets_and_ar.html#modelos-autoregressivos-ar",
    "href": "content/pt/part1/ets_and_ar.html#modelos-autoregressivos-ar",
    "title": "4  Modelos estatísticos clássicos e diferenciação",
    "section": "4.2 Modelos autoregressivos (AR)",
    "text": "4.2 Modelos autoregressivos (AR)\nModelos autoregressivos (AR) são modelos que prevem o valor atual de uma série temporal como uma combinação dos valores passados. O modelo AR(p) usa os últimos p valores para fazer a previsão:\n\\[\n\\hat{Y}(t) = \\phi_1 Y(t-1) + \\phi_2 Y(t-2) + \\dots + \\phi_p Y(t-p)\n\\]\nonde \\(\\phi_1, \\phi_2, \\dots, \\phi_p\\) são os parâmetros do modelo que precisam ser estimados a partir dos dados.\n\nfrom sktime.forecasting.auto_reg import AutoREG\nfrom sktime.utils.plotting import plot_series\n\nmodel = AutoREG(lags=31)\nmodel.fit(y_train)\n\ny_pred = model.predict(fh=y_test.index)\nplot_series(\n    y_train,\n    y_test,\n    y_pred,\n    labels=[\"Treino\", \"Teste\", \"Previsão AR\"],\n)\n\n\n\n\n\n\n\n\nUm modelo auto-regressivo mais complexo é o ARIMA, que combina autoregressão (AR), média móvel (MA) e diferenciação integrada (I) para lidar com séries temporais não estacionárias. Não vamos estudar o ARIMA aqui pois envolve conceitos mais avançados, mas temos ele disponível no sktime, sktime.forecasting.arima.ARIMA.",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelos estatísticos clássicos e diferenciação</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/ets_and_ar.html#stl-dividir-e-conquistar",
    "href": "content/pt/part1/ets_and_ar.html#stl-dividir-e-conquistar",
    "title": "4  Modelos estatísticos clássicos e diferenciação",
    "section": "4.3 STL: dividir e conquistar",
    "text": "4.3 STL: dividir e conquistar\nSabemos que séries temporais podem ser decompostas em componentes de tendência, sazonalidade e resíduos. O modelo STL (Seasonal and Trend decomposition using Loess) é uma técnica que permite fazer essa decomposição de forma robusta.\nTemos no sktime o STLTransformer, que permite fazer a decomposição STL:\n\nfrom sktime.transformations.series.detrend import STLTransformer\n\nstl = STLTransformer(sp=365)\nstl.fit(y_train)\n\nSTLTransformer(sp=365)Please rerun this cell to show the HTML repr or trust the notebook.STLTransformer?Documentation for STLTransformerSTLTransformer(sp=365)\n\n\nE agora podemos inspecionar os componentes:\n\nfig, ax = plt.subplots(3, 1, figsize=(10, 8), sharex=True)\nstl.trend_.plot.line(ax=ax[0])\nax[0].set_title(\"Tendência\")\nstl.seasonal_.plot.line(ax=ax[1])\nax[1].set_title(\"Sazonalidade\")\nstl.resid_.plot.line(ax=ax[2])\nax[2].set_title(\"Resíduos\")\nfig.show()\n\n\n\n\n\n\n\n\nUma possibilidade, uma vez que temos os diferentes componentes, é modelar cada componente separadamente e depois combinar as previsões. O sktime tem o STLForecaster, que faz exatamente isso:\n\nfrom sktime.forecasting.trend import STLForecaster\nfrom sktime.forecasting.naive import NaiveForecaster\n\nmodel = STLForecaster(\n    forecaster_trend=AutoREG(lags=31),\n    forecaster_seasonal=NaiveForecaster(sp=7),\n    forecaster_resid=AutoREG(lags=31),\n    sp=7,\n)\n\nmodel.fit(y_train)\ny_pred = model.predict(fh=y_test.index)\n\nplot_series(\n    y_train,\n    y_test,\n    y_pred,\n    labels=[\"Treino\", \"Teste\", \"Previsão STL + AR\"],\n)\n\n\n\n\n\n\n\n\nPara fins de demonstração, podemos complicar um pouco mais o modelo, modelando os resíduos com outro STLForecaster:\n\nmodel = STLForecaster(\n    forecaster_trend=AutoREG(lags=31),\n    forecaster_seasonal=NaiveForecaster(sp=7),\n    forecaster_resid=STLForecaster(\n        forecaster_trend=AutoREG(lags=31),\n        forecaster_seasonal=NaiveForecaster(sp=365),\n        forecaster_resid=AutoREG(lags=31),\n        sp=365,\n    ),\n    sp=7,\n)\n\nmodel.fit(y_train)\n\nSTLForecaster(forecaster_resid=STLForecaster(forecaster_resid=AutoREG(lags=31),\n                                             forecaster_seasonal=NaiveForecaster(sp=365),\n                                             forecaster_trend=AutoREG(lags=31),\n                                             sp=365),\n              forecaster_seasonal=NaiveForecaster(sp=7),\n              forecaster_trend=AutoREG(lags=31), sp=7)Please rerun this cell to show the HTML repr or trust the notebook.STLForecaster?Documentation for STLForecasterSTLForecaster(forecaster_resid=STLForecaster(forecaster_resid=AutoREG(lags=31),\n                                             forecaster_seasonal=NaiveForecaster(sp=365),\n                                             forecaster_trend=AutoREG(lags=31),\n                                             sp=365),\n              forecaster_seasonal=NaiveForecaster(sp=7),\n              forecaster_trend=AutoREG(lags=31), sp=7)forecaster_resid: STLForecasterSTLForecaster(forecaster_resid=AutoREG(lags=31),\n              forecaster_seasonal=NaiveForecaster(sp=365),\n              forecaster_trend=AutoREG(lags=31), sp=365)forecaster_resid: AutoREGAutoREG(lags=31)AutoREG?Documentation for AutoREGAutoREG(lags=31)forecaster_seasonal: NaiveForecasterNaiveForecaster(sp=365)NaiveForecaster?Documentation for NaiveForecasterNaiveForecaster(sp=365)forecaster_trend: AutoREGAutoREG(lags=31)AutoREG?Documentation for AutoREGAutoREG(lags=31)forecaster_seasonal: NaiveForecasterNaiveForecaster(sp=7)NaiveForecaster?Documentation for NaiveForecasterNaiveForecaster(sp=7)forecaster_trend: AutoREGAutoREG(lags=31)AutoREG?Documentation for AutoREGAutoREG(lags=31)\n\n\n\ny_pred = model.predict(fh=y_test.index)\n\nplot_series(\n    y_train,\n    y_test,\n    y_pred,\n    labels=[\"Treino\", \"Teste\", \"Previsão STL + AR\"],\n)\n\n\n\n\n\n\n\n\n\n\n\n\nHyndman, Rob J, and George Athanasopoulos. 2018. Forecasting: Principles and Practice. OTexts.",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelos estatísticos clássicos e diferenciação</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/metricas.html",
    "href": "content/pt/part1/metricas.html",
    "title": "5  Métricas e cross-validation",
    "section": "",
    "text": "5.1 Métricas\nAté então, vimos como criar modelos de séries temporais e avaliamos qualitativamente seu desempenho, em apenas uma simples divisão treino-teste. Agora, vamos explorar como avaliar modelos de séries temporais de forma mais robusta, utilizando métricas específicas e técnicas de validação cruzada adaptadas para dados temporais.\nPrimeiro vamos baixar os dados e criar um modelo simples.\nimport matplotlib.pyplot as plt\nfrom tsbook.datasets.retail import SyntheticRetail\nfrom sktime.utils.plotting import plot_series\nfrom sktime.forecasting.naive import NaiveForecaster\n\ndataset = SyntheticRetail(\"univariate\")\ny_train, y_test = dataset.load(\"y_train\", \"y_test\")\n\n# Predict\nmodel = NaiveForecaster(strategy=\"last\")\nmodel.fit(y_train)\ny_pred = model.predict(fh=y_test.index)\nPara avaliar o desempenho de modelos de séries temporais, existem diversas métricas que podem ser utilizadas.\nDuas métricas básicas são:\nfrom sktime.performance_metrics.forecasting import MeanAbsoluteError\n\nmetric = MeanAbsoluteError()\nmetric(y_true=y_test, y_pred=y_pred)\n\nnp.float64(614.9555555555555)\n\\[\nMSE = \\frac{1}{h} \\sum_{t=T+1}^{T+h} (y_t - \\hat{y}_t)^2\n\\]\nfrom sktime.performance_metrics.forecasting import MeanSquaredError\n\nmetric = MeanSquaredError()\nmetric(y_true=y_test, y_pred=y_pred)\n\nnp.float64(633516.4555555555)\nNo entanto, essas métricas não levam em consideração a escala dos dados, o que pode ser um problema ao comparar desempenho entre diferentes séries temporais, e também na comunicação dos resultados para stakeholders.\nEm muitos meios, é comum usar métricas que eliminam o fator escala, como:\n\\[\nMAPE = \\frac{1}{h} \\sum_{t=T+1}^{T+h} \\left| \\frac{y_t - \\hat{y}_t}{y_t} \\right|\n\\]\nfrom sktime.performance_metrics.forecasting import MeanAbsolutePercentageError\n\nmetric = MeanAbsolutePercentageError()\nmetric(y_true=y_test, y_pred=y_pred)\n\nnp.float64(0.21289989268196857)\nmetric = MeanAbsolutePercentageError(symmetric=True)\nmetric(y_true=y_test, y_pred=y_pred)\n\nnp.float64(0.22352456623275035)\n\\[\nsMAPE = \\frac{1}{h} \\sum_{t=T+1}^{T+h} \\frac{|y_t - \\hat{y}_t|}{(|y_t| + |\\hat{y}_t|)/2}\n\\]\nEssas métricas, no entanto, apresentam seus próprios problemas. Note que os valores podem ser exageradamente alto quando o denominador é próximo de zero. Ou seja, o MAPE e sMAPE podem ser problemáticos quando a série temporal contém valores próximos de zero.\nOutro tema é que essas métricas não consideram a dificuldade da série. Por exemplo, 5% de erro pode ser muito em uma série, e pouco em outra. Para isso, foram propostas métricas “escalas”:\n\\[\ne_{naive} = \\frac{1}{T-1} \\sum_{t=2}^{T} |y_t - y_{t-1}|\n\\]\nsão os erros nos dados de treino, então:\n\\[\nMASE = \\frac{1}{h} \\sum_{t=T+1}^{T+h} \\frac{|y_t - \\hat{y}_t|}{e_{naive}}\n\\]\nfrom sktime.performance_metrics.forecasting import MeanAbsoluteScaledError\n\nmetric = MeanAbsoluteScaledError()\nmetric(y_true=y_test, y_pred=y_pred, y_train=y_train)\n\nnp.float64(10.123559926834387)\n\\[\nMSSE = \\frac{1}{h} \\sum_{t=T+1}^{T+h} \\frac{(y_t - \\hat{y}_t)^2}{e_{naive}^2}\n\\]\nfrom sktime.performance_metrics.forecasting import MeanSquaredScaledError\n\nmetric = MeanSquaredScaledError()\nmetric(y_true=y_test, y_pred=y_pred, y_train=y_train)\n\nnp.float64(57.07280843131573)",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Métricas e cross-validation</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/metricas.html#métricas",
    "href": "content/pt/part1/metricas.html#métricas",
    "title": "5  Métricas e cross-validation",
    "section": "",
    "text": "Mean Absolute Error (MAE): Média dos erros absolutos entre as previsões e os valores reais. \\[\nMAE = \\frac{1}{h} \\sum_{t=T+1}^{T+h} |y_t - \\hat{y}_t|\n\\]\n\n\n\nMean Squared Error (MSE): Média dos erros quadráticos entre as previsões e os valores reais.\n\n\n\n\n\n\nMean Absolute Percentage Error (MAPE): Média dos erros percentuais absolutos entre as previsões e os valores reais.\n\n\n\n\nSymmetric Mean Absolute Percentage Error (sMAPE): Média dos erros percentuais absolutos simétricos entre as previsões e os valores reais.\n\n\n\n\n\n\nMean Absolute Scaled Error (MASE): dividimos o erro absoluto pelo erro absoluto médio de um naive nos dados de treino. Se:\n\n\n\n\n\n\nMean Squared Scaled Error (MSSE): dividimos o erro quadrático pelo quadrado de \\(e_{naive}\\).",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Métricas e cross-validation</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/metricas.html#cross-validation-para-séries-temporais",
    "href": "content/pt/part1/metricas.html#cross-validation-para-séries-temporais",
    "title": "5  Métricas e cross-validation",
    "section": "5.2 Cross-validation para séries temporais",
    "text": "5.2 Cross-validation para séries temporais\nEm um cross-validation, nossa intenção é estimar corretamente o erro de generalização do modelo, ou seja, o erro que o modelo terá em dados futuros.\n\\[\n\\mathbb{E}[L(Y, \\hat{Y})]\n\\]\nOnde a média é sobre a distribuição que mais representa o que será visto em produção.\nTipicamente, fazemos back-testing com dois tipos de janelas:\n\nSliding window: a janela de treino tem tamanho fixo, e “desliza” ao longo do tempo. A cada passo, o modelo é re-treinado com os dados mais recentes.\n\n\nfrom sktime.utils.plotting import plot_windows\n\nfrom sktime.split import SlidingWindowSplitter\n\nsliding_window_cv = SlidingWindowSplitter(\n    window_length=365 * 3, step_length=100, fh=list(range(1, 90 + 1))\n)\nplot_windows(cv=sliding_window_cv, y=y_train)\nplt.show()\n\n\n\n\n\n\n\n\n\nExpanding window: a janela de treino começa com um tamanho mínimo, e vai aumentando ao longo do tempo, incluindo todos os dados anteriores. A cada passo, o modelo é re-treinado com todos os dados disponíveis até aquele ponto.\n\n\nfrom sktime.split import ExpandingWindowSplitter\n\n\n\nexpanding_window_cv = ExpandingWindowSplitter(\n    initial_window=365 * 3, step_length=100, fh=list(range(1, 90 + 1))\n)\nplot_windows(cv=expanding_window_cv, y=y_train)\nplt.show()\n\n\n\n\n\n\n\n\n\nQual escolher? Bom, escolha o que mais representa o que você espera ver em produção.",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Métricas e cross-validation</span>"
    ]
  },
  {
    "objectID": "content/pt/part1/metricas.html#executando-o-cross-validation",
    "href": "content/pt/part1/metricas.html#executando-o-cross-validation",
    "title": "5  Métricas e cross-validation",
    "section": "5.3 Executando o cross-validation",
    "text": "5.3 Executando o cross-validation\nPara executar cross-validation, usamos a função evaluate, que recebe o modelo, o esquema de cross-validation, os dados, e a métrica a ser usada.\n\nfrom sktime.forecasting.model_evaluation import evaluate\nfrom sktime.performance_metrics.forecasting import MeanAbsoluteScaledError\nfrom sktime.forecasting.naive import NaiveForecaster\n\nmodel = NaiveForecaster(strategy=\"last\")\n\nevaluate(\n    forecaster=model,\n    cv=expanding_window_cv,\n    y=y_train,\n    X=None, # Veremos na próxima seçao!\n    scoring=MeanAbsoluteScaledError(),\n    error_score=\"raise\",\n    return_data=True,\n)\n\n\n\n\n\n\n\n\ntest_MeanAbsoluteScaledError\nfit_time\npred_time\nlen_train_window\ncutoff\ny_train\ny_test\ny_pred\n\n\n\n\n0\n12.834619\n0.004345\n0.010120\n1095\n2022-12-30\nsales date 2020-01-01...\nsales date 2022-12-31...\nsales 2022-12-31 458.0 2023-01-01...\n\n\n1\n3.808715\n0.003967\n0.009625\n1195\n2023-04-09\nsales date 2020-01-01...\nsales date 2023-04-10...\nsales 2023-04-10 866.0 2023-04-11...\n\n\n2\n8.057811\n0.004040\n0.009489\n1295\n2023-07-18\nsales date 2020-01-01...\nsales date 2023-07-19...\nsales 2023-07-19 748.0 2023-07-20...\n\n\n3\n7.854351\n0.003864\n0.009340\n1395\n2023-10-26\nsales date 2020-01-01...\nsales date 2023-10-27...\nsales 2023-10-27 1229.0 2023-10-...\n\n\n4\n5.956618\n0.003974\n0.009426\n1495\n2024-02-03\nsales date 2020-01-01...\nsales date 2024-02-04...\nsales 2024-02-04 1915.0 2024-02-...",
    "crumbs": [
      "Part I: Básico",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Métricas e cross-validation</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/exog_variables.html",
    "href": "content/pt/part2/exog_variables.html",
    "title": "6  Variáveis Exógenas",
    "section": "",
    "text": "6.1 Tipos de Variáveis Exógenas\nComo séries temporais possuem uma ordem temporal, a sua própria história tem poder preditivo muito forte. No entanto, em alguns casos, apenas a história não é suficiente para fazer previsões precisas.\nPor exemplo, em vendas de varejo, fatores como promoções, feriados e eventos sazonais podem impactar significativamente as vendas.\nAgora, vamos ver como usar variáveis exógenas em modelos de séries temporais com sktime, as famosas “features”.\nA interface é sempre a mesma, vamos ver que a diferença é o uso do parâmetro X nos métodos fit e predict.\nUsaremos os mesmos dados de varejo sintético dos exemplos anteriores. Agora, teremos também X_train e X_test, que são as variáveis exógenas.\nNem todos modelos suportam variáveis exógenas. Para ver uma lista de possibilidades, podemos usar a função all_estimators do sktime.\nAntes de prosseguirmos, vamos separar as variáveis exógenas em dois tipos:\nNesse último cenário, para realizar a previsão, existem três opções: 1. Prever os valores futuros das variáveis exógenas usando um modelo separado (ou o mesmo modelo, se ele permitir) e usar essas previsões como entrada para o modelo principal de previsão. 2. Usar um valor de preenchimento (por exemplo, o último valor conhecido) para as variáveis exógenas de valor futuro desconhecido durante a previsão. 3. Usar valores defasados (lags) das variáveis exógenas como características (features), o que pode ser útil se o modelo conseguir aprender com os valores passados dessas variáveis.",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Variáveis Exógenas</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/exog_variables.html#tipos-de-variáveis-exógenas",
    "href": "content/pt/part2/exog_variables.html#tipos-de-variáveis-exógenas",
    "title": "6  Variáveis Exógenas",
    "section": "",
    "text": "Variáveis exógenas com valores futuros conhecidos: São variáveis cujos valores futuros já são conhecidos no momento da previsão. Variáveis indicadoras (dummies) para feriados ou eventos especiais, bem como recursos de sazonalidade, são exemplos comuns desse tipo de variável.\nVariáveis exógenas com valores futuros desconhecidos: São variáveis cujos valores futuros não são conhecidos para o horizonte de previsão. Por exemplo, se quisermos incluir indicadores econômicos que ainda não foram divulgados, devemos tratá-los como variáveis exógenas de valor futuro desconhecido.",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Variáveis Exógenas</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/exog_variables.html#usando-variáveis-exógenas-com-sktime",
    "href": "content/pt/part2/exog_variables.html#usando-variáveis-exógenas-com-sktime",
    "title": "6  Variáveis Exógenas",
    "section": "6.2 Usando variáveis exógenas com sktime",
    "text": "6.2 Usando variáveis exógenas com sktime\nVamos usar AutoREG como modelo base para nosso exemplo de vairáveis exógenas. Primeiramente, vamos supor que conhecemos a variável macro_trend no futuro\n\nfrom sktime.forecasting.auto_reg import AutoREG\n\nmodel = AutoREG(lags=30)\nmodel.fit(y_train, X=X_train)\ny_pred = model.predict(fh=y_test.index, X=X_test)\n\n\nplot_series(y_train, y_test, y_pred, labels=[\"Treino\", \"Teste\", \"Previsão com Exógenas\"])\n\n\n\n\n\n\n\n\nFácil, no caso que conhecemos a variável exógena no futuro, basta passar X em fit e predict.\nAntes de avançar, é importante revisar que os transformadores com fit e transform também podem ser aplicados a variávei exógenas! Inclusive, podemos fazer pipelines compostos de várias etapas de preprocessamento de exógenas. Isso será importante para os próximos exemplos.",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Variáveis Exógenas</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/exog_variables.html#variável-observada-mas-desconhecida-no-futuro",
    "href": "content/pt/part2/exog_variables.html#variável-observada-mas-desconhecida-no-futuro",
    "title": "6  Variáveis Exógenas",
    "section": "6.3 Variável observada, mas desconhecida no futuro",
    "text": "6.3 Variável observada, mas desconhecida no futuro\nVamos eliminar a variável macro_trend do conjunto de teste, para simular o cenário onde não conhecemos o valor futuro dessa variável.\n\nimport numpy as np\n\nX_test_missing = X_test.copy()\nX_test_missing[\"macro_trend\"] = np.nan\n\n\n6.3.1 Solução 1: Prever a variável exógena\nAgora, vamos supor que não sabemos o valor futuro de macro_trend. Nesse caso, podemos criar um modelo separado para prever macro_trend e usar essa previsão como entrada para o modelo principal.\nSktime possui uma funcionalidade pronta para isso: um forecaster chamado ForecastX. Ele é composto de dois modelos, um para a variável exógena, e outro para o alvo principal.\nAqui, o forecaster necessita que o horizonte de previsão (fh) seja passado já na etapa de fit.\n\nfrom sktime.forecasting.compose import ForecastX\n\nmodel = ForecastX(\n    forecaster_y=AutoREG(lags=30),\n    forecaster_X=AutoREG(lags=30),\n)\n\nfh = [i for i in range(1, len(y_test) + 1)]\nmodel.fit(y_train, X=X_train, fh=fh)\n\ny_pred_case1 = model.predict(X=X_test_missing)\n\n\nplot_series(y_train, y_test, y_pred_case1, labels=[\"Treino\", \"Teste\", \"Previsão com Exógenas Previstas\"])\n\n\n\n\n\n\n\n\n\n\n6.3.2 Solução 2: Usar valor de preenchimento (imputação)\nPara essa solução, vamos usar transformadores para preencher os valores faltantes na variável exógena. Aqui, usaremos o Imputer do sktime, que suporta variáveis exógenas.\n\nfrom sktime.transformations.series.impute import Imputer\nimputer = Imputer(method=\"mean\")\nimputer.fit(X_train)\n\n# Agora imputamos\nX_test_imputed = imputer.transform(X_test_missing)\nX_test_imputed.tail()\n\n\n\n\n\n\n\n\npromo\nmacro_trend\n\n\ndate\n\n\n\n\n\n\n2024-12-28\n0.0\n22.809251\n\n\n2024-12-29\n0.0\n22.809251\n\n\n2024-12-30\n0.0\n22.809251\n\n\n2024-12-31\n1.0\n22.809251\n\n\n2025-01-01\n0.0\n22.809251\n\n\n\n\n\n\n\nPara usar preprocessamento de exógenas + forecasting, podemos usar a composição ForecastingPipeline.\n\nfrom sktime.forecasting.compose import ForecastingPipeline\nfrom sktime.transformations.series.difference import Differencer\n\n\nmodel = ForecastingPipeline(\n    steps=[(\"imputer\", Imputer(method=\"mean\")), (\"forecaster\", AutoREG(lags=30))]\n)\nmodel.fit(y_train, X=X_train)\n\nForecastingPipeline(steps=[('imputer', Imputer(method='mean')),\n                           ('forecaster', AutoREG(lags=30))])Please rerun this cell to show the HTML repr or trust the notebook.ForecastingPipeline?Documentation for ForecastingPipelineForecastingPipeline(steps=[('imputer', Imputer(method='mean')),\n                           ('forecaster', AutoREG(lags=30))])Imputer?Documentation for ImputerImputer(method='mean')AutoREG?Documentation for AutoREGAutoREG(lags=30)\n\n\n\ny_pred_case2 = model.predict(fh=y_test.index, X=X_test_missing)\nplot_series(y_train, y_test, y_pred_case2, labels=[\"Treino\", \"Teste\", \"Previsão com Exógenas Imputadas\"])\n\n\n\n\n\n\n\n\nNossa previsão não ficou boa. Claro! A variável exógena possui uma tendência - que naturalmente faz com que a imputação do ultimo valor ou a média não funcione bem. A solução ótima varia de caso para caso.\n\n\n\n\n\n\nTip\n\n\n\nDica: Podemos também usar o operador ** como atalho para criar pipelines de variáveis exógenas.\nmodel = Imputer(method=\"mean\") ** AutoREG(lags=30)\nNote a diferença do que aprendemos para criar pipelines com transformações na variável target, que usam * como operador. Claramente, podemos fazer composições mais complexas, como:\nmodel = Imputer(method=\"mean\") ** (Differencer() * AutoREG())\n\n\n\n\n6.3.3 Solução 3: Usar valores defasados (lags) da variável exógena\nOutra opção é criar versões defasadas das variáveis exógenas e usá-las como features.\nPara isso, podemos usar o transformador Lag do sktime. Ao utilizar defasagens (lags), surgem dois desafios principais:\n\nO aparecimento de valores NaN, que muitos modelos de previsão não conseguem tratar.\nO número de variáveis exógenas pode aumentar significativamente, o que pode levar a overfitting ou, no caso do nosso conjunto de dados, a um número de features maior que o número de amostras — o que pode gerar erros no processo de ajuste (fitting).\n\nPara lidar com isso, no exemplo abaixo utilizamos um TransformerPipeline que realiza as seguintes etapas:\n\nSeleção de variáveis: executa uma seleção das variáveis exógenas, mantendo apenas as mais relevantes.\nDefasagem: aplica o transformador Lag para criar versões defasadas das variáveis exógenas.\nImputação: usa o transformador Imputer para preencher os valores NaN criados pelo processo de defasagem. Neste caso, é usado o método backfill (preenchimento a partir de valores posteriores).\n\n\nfrom sktime.transformations.compose import TransformerPipeline\nfrom sktime.transformations.series.feature_selection import FeatureSelection\nfrom sktime.transformations.series.impute import Imputer\nfrom sktime.transformations.series.lag import Lag\nfrom sktime.transformations.series.subset import IndexSubset\n\n\ntransformer_pipeline = TransformerPipeline(\n    steps=[\n        (\"lag\", Lag(lags=list(range(1, 180 + 1)))),  # Cria lags 3 e 4\n        (\"subset\", IndexSubset()),  # Seleciona apenas macro_trend\n        (\"impute\", Imputer(method=\"backfill\", value=0)),  # Imputa valores NaN\n        (\"feature_selection\", FeatureSelection()),  # Seleciona features\n    ]\n)\n\n\ntransformer_pipeline.fit(X=X_train, y=y_train)\nX_test_transformed = transformer_pipeline.transform(X=X_test_missing)\n\nX_test_transformed.head()\n\n\n\n\n\n\n\n\nlag_98__macro_trend\nlag_34__macro_trend\nlag_35__macro_trend\nlag_85__macro_trend\nlag_53__macro_trend\nlag_104__macro_trend\nlag_6__macro_trend\nlag_79__macro_trend\nlag_67__macro_trend\nlag_89__macro_trend\n...\nlag_75__promo\nlag_50__macro_trend\nlag_105__promo\nlag_150__promo\nlag_91__macro_trend\nlag_166__promo\nlag_66__promo\nlag_145__promo\nlag_158__macro_trend\nlag_117__promo\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2024-07-06\n82.242222\n81.715111\n82.046222\n82.696889\n82.467556\n81.645333\n82.914667\n82.837778\n81.768000\n82.435556\n...\n0.0\n82.733333\n1.0\n0.0\n82.636444\n0.0\n0.0\n0.0\n71.546222\n0.0\n\n\n2024-07-07\n82.296444\n81.827556\n81.715111\n82.895111\n82.515111\n81.672000\n83.159111\n82.793333\n81.884889\n82.302222\n...\n0.0\n82.888444\n0.0\n0.0\n82.547111\n0.0\n0.0\n0.0\n71.872444\n0.0\n\n\n2024-07-08\n82.327556\n82.088000\n81.827556\n82.973333\n82.639556\n81.734222\n83.445778\n82.500444\n82.067556\n82.296444\n...\n0.0\n82.800000\n0.0\n0.0\n82.435556\n0.0\n0.0\n0.0\n72.169333\n0.0\n\n\n2024-07-09\n82.401778\n82.558667\n82.088000\n82.860444\n82.733333\n81.885333\n83.599556\n82.027111\n82.179111\n82.467111\n...\n0.0\n82.740444\n0.0\n0.0\n82.302222\n0.0\n0.0\n0.0\n72.259556\n0.0\n\n\n2024-07-10\n82.391556\n82.660444\n82.558667\n82.744000\n82.888444\n82.095111\n83.727111\n81.541333\n82.292889\n82.696889\n...\n0.0\n82.797333\n0.0\n0.0\n82.296444\n0.0\n0.0\n0.0\n72.433778\n0.0\n\n\n\n\n5 rows × 180 columns\n\n\n\n\nmodel = ForecastingPipeline(\n    steps=[\n        (\"preprocessing\", transformer_pipeline),\n        (\"forecaster\", AutoREG(lags=30)),\n    ]\n).fit(X=X_train, y=y_train)\n\n\nmodel\n\nForecastingPipeline(steps=[('preprocessing',\n                            TransformerPipeline(steps=[('lag',\n                                                        Lag(lags=[1, 2, 3, 4, 5,\n                                                                  6, 7, 8, 9,\n                                                                  10, 11, 12,\n                                                                  13, 14, 15,\n                                                                  16, 17, 18,\n                                                                  19, 20, 21,\n                                                                  22, 23, 24,\n                                                                  25, 26, 27,\n                                                                  28, 29, 30, ...])),\n                                                       ('subset',\n                                                        IndexSubset()),\n                                                       ('impute',\n                                                        Imputer(method='backfill',\n                                                                value=0)),\n                                                       ('feature_selection',\n                                                        FeatureSelection())])),\n                           ('forecaster', AutoREG(lags=30))])Please rerun this cell to show the HTML repr or trust the notebook.ForecastingPipeline?Documentation for ForecastingPipelineForecastingPipeline(steps=[('preprocessing',\n                            TransformerPipeline(steps=[('lag',\n                                                        Lag(lags=[1, 2, 3, 4, 5,\n                                                                  6, 7, 8, 9,\n                                                                  10, 11, 12,\n                                                                  13, 14, 15,\n                                                                  16, 17, 18,\n                                                                  19, 20, 21,\n                                                                  22, 23, 24,\n                                                                  25, 26, 27,\n                                                                  28, 29, 30, ...])),\n                                                       ('subset',\n                                                        IndexSubset()),\n                                                       ('impute',\n                                                        Imputer(method='backfill',\n                                                                value=0)),\n                                                       ('feature_selection',\n                                                        FeatureSelection())])),\n                           ('forecaster', AutoREG(lags=30))])preprocessing?Documentation for preprocessingTransformerPipeline(steps=[('lag',\n                            Lag(lags=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n                                      24, 25, 26, 27, 28, 29, 30, ...])),\n                           ('subset', IndexSubset()),\n                           ('impute', Imputer(method='backfill', value=0)),\n                           ('feature_selection', FeatureSelection())])Lag?Documentation for LagLag(lags=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n          21, 22, 23, 24, 25, 26, 27, 28, 29, 30, ...])IndexSubset?Documentation for IndexSubsetIndexSubset()Imputer?Documentation for ImputerImputer(method='backfill', value=0)FeatureSelection?Documentation for FeatureSelectionFeatureSelection()AutoREG?Documentation for AutoREGAutoREG(lags=30)\n\n\n\ny_pred_case3 = model.predict(fh=y_test.index, X=X_test_missing)\nplot_series(y_train, y_test, y_pred_case3, labels=[\"Treino\", \"Teste\", \"Previsão com Exógenas Lag\"])",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Variáveis Exógenas</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/ml_models.html",
    "href": "content/pt/part2/ml_models.html",
    "title": "7  Modelos de Machine Learning",
    "section": "",
    "text": "7.1 O problema da tendência\nNesse capítulo vamos ver as maneiras de usar modelos de Machine Learning para forecasting. Aqui é onde mais acontecem erros de novos praticantes, pois muitas vezes tentam aplicar modelos de ML diretamente na série temporal.\nPara usar um modelo de ML, precisamos transformar a série temporal em um problema de regressão tradicional. Isso é feito criando janelas deslizantes (sliding windows) da série temporal, onde cada janela é usada como uma amostra de treinamento para o modelo de ML.\nOu seja, se temos uma série temporal \\((y_t)\\), podemos criar janelas de tamanho \\(n\\) e usar os valores \\(y_{t-n}, y_{t-n+1}, \\ldots, y_{t-1}\\) como características (features) para prever o valor \\(y_t\\).\nPara prever mais de um passo à frente, existem duas abordagens:\nA verdade é que as duas abordagens podem ser vistas como uma: a previsão recursiva pode ser vista como uma previsão direta para \\(h=1\\).\nA tendência em séries temporais é como um constante problema de data drift:\nCode\n_X = [y_train.iloc[i : i + 7] for i in range(0, 700)]\n\n_X_test = [y_train.iloc[i : i + 7] for i in range(700, 800)]\n\n\ndef set_index(x):\n    x.index = range(len(x))\n    return x\n\n\n_X = [set_index(x) for x in _X]\n_X_test = [set_index(x) for x in _X_test]\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nfor x in _X:\n    ax.plot(x, color=\"gray\", alpha=0.3)\nfor x in _X_test:\n    ax.plot(x, color=\"red\", alpha=0.3)\n\n# Add legend, with 1 red line for test and 1 gray for train\nfrom matplotlib.lines import Line2D\n\nlegend_handles = [\n    Line2D([0], [0], color=\"gray\", alpha=0.3, lw=2, label=\"Treino\"),\n    Line2D([0], [0], color=\"red\", alpha=0.3, lw=2, label=\"Teste\"),\n]\nax.legend(handles=legend_handles, loc=\"best\")\nax.set_title(\"Série original - Magnitudes diferentes para cada janela\")\nfig.show()\nQuando criamos nossas janelas e olhamos treine e teste, esse problema fica claro. A informação de uma série em treino não é util para prever a série de teste, pois elas estão em magnitudes diferentes.\nUma possível solução para isso é normalizar cada janela, dividindo pelo valor médio da janela. Assim, todas as janelas ficam na mesma escala:\nCode\n_X = [x / x.mean() for x in _X]\n_X_test = [x / x.mean() for x in _X_test]\n\nfig, ax = plt.subplots()\nfor x in _X:\n    ax.plot(x, color=\"gray\", alpha=0.3)\nfor x in _X_test:\n    ax.plot(x, color=\"red\", alpha=0.3)\n\nax.legend(handles=legend_handles, loc=\"best\")\nax.set_title(\"Série normalizada\")\nfig.show()\ne podemos prever sem problemas.\nOutra possibilidade é a diferenciação, como já vimos em capítulos anteriores. A diferenciação remove a tendência da série, tornando-a estacionária.",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modelos de Machine Learning</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/ml_models.html#usando-modelos-de-ml-com-sktime",
    "href": "content/pt/part2/ml_models.html#usando-modelos-de-ml-com-sktime",
    "title": "7  Modelos de Machine Learning",
    "section": "7.2 Usando modelos de ML com sktime",
    "text": "7.2 Usando modelos de ML com sktime\nPrimeiro, vamos import ReductionForecaster, que é a classe que implementa a abordagem de janelas deslizantes para usar modelos de ML em séries temporais. Vamos testar um primeiro caso sem nenhum tipo de preprocessamento, apenas criando as janelas:\n\nfrom tsbook.forecasting.reduction import ReductionForecaster\nfrom lightgbm import LGBMRegressor\n\nmodel = ReductionForecaster(\n    LGBMRegressor(n_estimators=100, random_state=42),\n    window_length=30,\n)\n\nmodel.fit(y_train, X=X_train)\n\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000118 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1618, number of used features: 31\n[LightGBM] [Info] Start training from score 580.323857\n\n\nReductionForecaster(estimator=LGBMRegressor(random_state=42), window_length=30)Please rerun this cell to show the HTML repr or trust the notebook.ReductionForecasterReductionForecaster(estimator=LGBMRegressor(random_state=42), window_length=30)estimator: LGBMRegressorLGBMRegressor(random_state=42)LGBMRegressorLGBMRegressor(random_state=42)\n\n\n\ny_pred = model.predict(fh=y_test.index, X=X_test)\nplot_series(y_train, y_test, y_pred, labels=[\"Treino\", \"Teste\", \"Previsão com ML\"])\nplt.show()\n\n\n\n\n\n\n\n\nClaramente, tivemos o problema que mencionamos anteriormente.\n\n7.2.1 Solução 1: Diferenciação\nUma solução é usar a diferenciação para remover a tendência da série.\n\nfrom sktime.transformations.series.difference import Differencer\n\nregressor = LGBMRegressor(n_estimators=100, random_state=42)\n\nmodel = Differencer() * ReductionForecaster(\n    regressor,\n    window_length=30,\n    steps_ahead=1,\n)\n\nmodel.fit(y_train, X=X_train)\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7638\n[LightGBM] [Info] Number of data points in the train set: 1618, number of used features: 31\n[LightGBM] [Info] Start training from score 1.496292\n\n\nTransformedTargetForecaster(steps=[Differencer(),\n                                   ReductionForecaster(estimator=LGBMRegressor(random_state=42),\n                                                       window_length=30)])Please rerun this cell to show the HTML repr or trust the notebook.TransformedTargetForecaster?Documentation for TransformedTargetForecasterTransformedTargetForecaster(steps=[Differencer(),\n                                   ReductionForecaster(estimator=LGBMRegressor(random_state=42),\n                                                       window_length=30)])Differencer?Documentation for DifferencerDifferencer()ReductionForecasterReductionForecaster(estimator=LGBMRegressor(random_state=42), window_length=30)estimator: LGBMRegressorLGBMRegressor(random_state=42)LGBMRegressorLGBMRegressor(random_state=42)\n\n\n\ny_pred_diff = model.predict(fh=y_test.index, X=X_test)\n\nplot_series(\n    y_train, y_test, y_pred_diff, labels=[\"Treino\", \"Teste\", \"Previsão com ML + Diferença\"]\n)\nplt.show()\n\n\n\n\n\n\n\n\nAqui, já vemos uma melhora significativa. Mas tem algo que podemos melhorar para realizar a diferenciação? Sim. Lembre que essa série tem um padrão multiplicativo. Então, antes de aplicar a diferenciação, podemos aplicar uma transformação logarítmica para estabilizar a variância:\n\nfrom sktime.transformations.series.boxcox import LogTransformer\n\nmodel_log = LogTransformer() * model\n\nmodel_log.fit(y_train, X=X_train)\ny_pred_log_diff = model_log.predict(fh=y_test.index, X=X_test)\nplot_series(\n    y_train,\n    y_test,\n    y_pred_log_diff,\n    labels=[\"Treino\", \"Teste\", \"Previsão com ML + Log + Diferença\"],\n)\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1618, number of used features: 31\n[LightGBM] [Info] Start training from score 0.002516\n\n\n\n\n\n\n\n\n\n\n\n7.2.2 Solução 2: Normalização por janela\nA diferenciação aumenta o ruído da série, o que pode dificultar o trabalho do modelo de ML. Outra opção é normalizar em cada janela. A classe ReductionForecaster tem um parâmetro chamado normalization_strategy, que pode ser usado para determinar a estratégia de normalização. Vamos usar a estratégia divide_mean, que divide cada janela pelo seu valor médio.\n\nmodel = ReductionForecaster(\n    regressor,\n    window_length=30,\n    steps_ahead=1,\n    normalization_strategy=\"divide_mean\",\n)\n\nmodel.fit(y_train, X=X_train)\ny_pred_norm = model.predict(fh=y_test.index, X=X_test)\n\nplot_series(\n    y_train, y_test, y_pred_norm, labels=[\"Treino\", \"Teste\", \"Previsão com ML + Normalização\"]\n)\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1618, number of used features: 31\n[LightGBM] [Info] Start training from score 1.043527\n\n\n\n\n\n\n\n\n\n\n\n7.2.3 Modelo direto e recursivo\nPodemos fazer um conjunto de modelos, um para cada passo à frente. Abaixo, definimos steps_ahead=12, o que significa que o modelo vai prever 12 passos à frente diretamente.\n\nmodel = ReductionForecaster(\n    regressor,\n    window_length=30,\n    steps_ahead=12,\n    normalization_strategy=\"divide_mean\",\n)\n\nmodel.fit(y_train, X=X_train)\ny_pred_norm_direct = model.predict(fh=y_test.index, X=X_test)\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1618, number of used features: 31\n[LightGBM] [Info] Start training from score 1.043527\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 31\n[LightGBM] [Info] Start training from score 1.047267\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1616, number of used features: 31\n[LightGBM] [Info] Start training from score 1.050587\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1615, number of used features: 31\n[LightGBM] [Info] Start training from score 1.053028\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1614, number of used features: 31\n[LightGBM] [Info] Start training from score 1.055194\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 31\n[LightGBM] [Info] Start training from score 1.057457\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 31\n[LightGBM] [Info] Start training from score 1.060191\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1611, number of used features: 31\n[LightGBM] [Info] Start training from score 1.063314\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1610, number of used features: 31\n[LightGBM] [Info] Start training from score 1.066550\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1609, number of used features: 31\n[LightGBM] [Info] Start training from score 1.069536\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1608, number of used features: 31\n[LightGBM] [Info] Start training from score 1.072317\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7652\n[LightGBM] [Info] Number of data points in the train set: 1607, number of used features: 31\n[LightGBM] [Info] Start training from score 1.074787\n\n\n\nplot_series(\n    y_train,\n    y_test,\n    y_pred_norm_direct,\n    labels=[\"Treino\", \"Teste\", \"Previsão com ML + Normalização\"],\n)\n\n\n\n\n\n\n\n\nPodemos comparar o MAPE de todos os modelos:\n\nfrom sktime.performance_metrics.forecasting import MeanAbsolutePercentageError\n\nmape = MeanAbsolutePercentageError()\n\nresults = {}\nfor _y_pred, label in zip(\n    [\n        y_pred,\n        y_pred_diff,\n        y_pred_log_diff,\n        y_pred_norm,\n        y_pred_norm_direct,\n    ],\n    [\n        \"ML\",\n        \"ML + Diferença\",\n        \"ML + Log + Diferença\",\n        \"ML + Normalização\",\n        \"ML + Normalização + Direto\",\n    ],\n):\n    results[label] = mape(y_test, _y_pred)\n\nimport pandas as pd\n\nresults = pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"MAPE\"])\nresults.sort_values(\"MAPE\")\n\n\n\n\n\n\n\n\nMAPE\n\n\n\n\nML + Normalização + Direto\n0.145813\n\n\nML + Log + Diferença\n0.153906\n\n\nML + Normalização\n0.156855\n\n\nML + Diferença\n0.231855\n\n\nML\n0.234599",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modelos de Machine Learning</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/panel_data.html",
    "href": "content/pt/part2/panel_data.html",
    "title": "8  Dados em painel (multi-series)",
    "section": "",
    "text": "8.1 Acessando os dados\nEm muitas aplicações, não temos acesso a uma única série temporal, mas sim a um conjunto de séries temporais relacionadas. Isso é comum em cenários como vendas de produtos em diferentes lojas, consumo de energia em diferentes regiões, etc. Esses dados são chamados de dados em painel.\nUma ideia poderosa é aproveitar a similaridade entre as séries para melhorar as previsões. Chamamos de modelos globais os modelos capazes de aprender padrões comuns entre as séries, ao contrário dos modelos locais que aprendem apenas com uma única série.\nA maioria dos modelos clássicos de séries temporais são locais. Modelos globais são, em geral, baseados em modelos tabulares de ML ou deep learning. Segundo competições de séries temporais, como a M5, em forecasts de painel os modelos globais são os que apresentam melhor desempenho (Makridakis, Spiliotis, and Assimakopoulos 2022).\nAqui, vamos usar o dataset sintético que vimos antes, mas agora teremos acesso às várias séries temporais que compõe o total.\nEsse dataset é feito para simular um caso de varejo, onde temos vendas diárias de vários produtos:\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sktime.utils.plotting import plot_series\nfrom tsbook.datasets.retail import SyntheticRetail\ndataset = SyntheticRetail(\"panel\")\ny_train, X_train, y_test, X_test = dataset.load(\n    \"y_train\", \"X_train\", \"y_test\", \"X_test\"\n)\nNote que, para dados em painel, os dataframes possuem mais um nível de índice, que identifica a série temporal a que cada observação pertence:\ndisplay(X_train)\n\n\n\n\n\n\n\n\n\npromo\n\n\nsku_id\ndate\n\n\n\n\n\n0\n2020-01-01\n0.0\n\n\n2020-01-02\n0.0\n\n\n2020-01-03\n0.0\n\n\n2020-01-04\n0.0\n\n\n2020-01-05\n0.0\n\n\n...\n...\n...\n\n\n24\n2024-07-01\n1.0\n\n\n2024-07-02\n0.0\n\n\n2024-07-03\n0.0\n\n\n2024-07-04\n0.0\n\n\n2024-07-05\n0.0\n\n\n\n\n41200 rows × 1 columns\nPodemos visualizar algumas séries. Vemos que há mais zeros nesse dataset, em comparação ao que usamos antes.\nfrom sktime.utils.plotting import plot_series\n\nfig, ax = plt.subplots(figsize=(10, 4))\ny_train.unstack(level=0).droplevel(0, axis=1).iloc[:, [0,10]].plot(ax=ax, alpha=0.7)\nplt.show()",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dados em painel (multi-series)</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/panel_data.html#acessando-os-dados",
    "href": "content/pt/part2/panel_data.html#acessando-os-dados",
    "title": "8  Dados em painel (multi-series)",
    "section": "",
    "text": "8.1.1 Pandas e multi-índices\nPara trabalhar com essas estruturas de dados, é importante revisar algumas operações do pandas.\n\ny_train.index.get_level_values(-1)\n\nPeriodIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04',\n             '2020-01-05', '2020-01-06', '2020-01-07', '2020-01-08',\n             '2020-01-09', '2020-01-10',\n             ...\n             '2024-06-26', '2024-06-27', '2024-06-28', '2024-06-29',\n             '2024-06-30', '2024-07-01', '2024-07-02', '2024-07-03',\n             '2024-07-04', '2024-07-05'],\n            dtype='period[D]', name='date', length=41200)\n\n\nAs seguintes operações são bem úteis para trabalhar com multi-índices:\n\ny_train.index\n\nMultiIndex([( 0, '2020-01-01'),\n            ( 0, '2020-01-02'),\n            ( 0, '2020-01-03'),\n            ( 0, '2020-01-04'),\n            ( 0, '2020-01-05'),\n            ( 0, '2020-01-06'),\n            ( 0, '2020-01-07'),\n            ( 0, '2020-01-08'),\n            ( 0, '2020-01-09'),\n            ( 0, '2020-01-10'),\n            ...\n            (24, '2024-06-26'),\n            (24, '2024-06-27'),\n            (24, '2024-06-28'),\n            (24, '2024-06-29'),\n            (24, '2024-06-30'),\n            (24, '2024-07-01'),\n            (24, '2024-07-02'),\n            (24, '2024-07-03'),\n            (24, '2024-07-04'),\n            (24, '2024-07-05')],\n           names=['sku_id', 'date'], length=41200)\n\n\nAcessar valores únicos no primeiro nivel (nível 0, mais à esquerda):\n\ny_train.index.get_level_values(0).unique()\n\nIndex([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24],\n      dtype='int64', name='sku_id')\n\n\nSelecionar uma série específica (nível 0 igual a 0):\n\ny_train.loc[0]\n\n\n\n\n\n\n\n\nsales\n\n\ndate\n\n\n\n\n\n2020-01-01\n0\n\n\n2020-01-02\n0\n\n\n2020-01-03\n0\n\n\n2020-01-04\n0\n\n\n2020-01-05\n0\n\n\n...\n...\n\n\n2024-07-01\n220\n\n\n2024-07-02\n128\n\n\n2024-07-03\n47\n\n\n2024-07-04\n73\n\n\n2024-07-05\n165\n\n\n\n\n1648 rows × 1 columns\n\n\n\nAqui, podemos usar pd.IndexSlice para selecionar várias séries ao mesmo tempo. Note que pd.IndexSlice é passado diretamente para .loc:\n\ny_train.loc[pd.IndexSlice[[0,2], :]]\n\n\n\n\n\n\n\n\n\nsales\n\n\nsku_id\ndate\n\n\n\n\n\n0\n2020-01-01\n0\n\n\n2020-01-02\n0\n\n\n2020-01-03\n0\n\n\n2020-01-04\n0\n\n\n2020-01-05\n0\n\n\n...\n...\n...\n\n\n2\n2024-07-01\n125\n\n\n2024-07-02\n185\n\n\n2024-07-03\n179\n\n\n2024-07-04\n210\n\n\n2024-07-05\n236\n\n\n\n\n3296 rows × 1 columns\n\n\n\nAgora, para selecionar o horizonte de forecasting, temos que chamar unique:\n\nfh = y_test.index.get_level_values(1).unique()\n\nfh\n\nPeriodIndex(['2024-07-06', '2024-07-07', '2024-07-08', '2024-07-09',\n             '2024-07-10', '2024-07-11', '2024-07-12', '2024-07-13',\n             '2024-07-14', '2024-07-15',\n             ...\n             '2024-12-23', '2024-12-24', '2024-12-25', '2024-12-26',\n             '2024-12-27', '2024-12-28', '2024-12-29', '2024-12-30',\n             '2024-12-31', '2025-01-01'],\n            dtype='period[D]', name='date', length=180)",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dados em painel (multi-series)</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/panel_data.html#upcasting-automático",
    "href": "content/pt/part2/panel_data.html#upcasting-automático",
    "title": "8  Dados em painel (multi-series)",
    "section": "8.2 Upcasting automático",
    "text": "8.2 Upcasting automático\nNem todos modelos suportam nativamente dados em painel. Por exemplo, exponential smoothing. Aqui, temos uma boa notícia: sem linhas extras necessárias. O sktime faz upcasting automático para dados em painel ao usar estimadores do sktime.\n\nfrom sktime.forecasting.naive import NaiveForecaster\n\n\nnaive_forecaster = NaiveForecaster(strategy=\"last\", window_length=1)\nnaive_forecaster.fit(y_train)\ny_pred_naive = naive_forecaster.predict(fh=fh)\n\ny_pred_naive\n\n\n\n\n\n\n\n\n\nsales\n\n\nsku_id\ndate\n\n\n\n\n\n0\n2024-07-06\n165.0\n\n\n2024-07-07\n165.0\n\n\n2024-07-08\n165.0\n\n\n2024-07-09\n165.0\n\n\n2024-07-10\n165.0\n\n\n...\n...\n...\n\n\n24\n2024-12-28\n209.0\n\n\n2024-12-29\n209.0\n\n\n2024-12-30\n209.0\n\n\n2024-12-31\n209.0\n\n\n2025-01-01\n209.0\n\n\n\n\n4500 rows × 1 columns\n\n\n\nInternamente, o sktime cria um clone do estimador para cada série nos dados em painel. Em seguida, cada clone é treinado com a série correspondente. Isso é feito de forma transparente para usuário, mas sem exigir esforço.\nO atributo forecasters_ armazena um DataFrame com os estimatores de cada série.\n\nnaive_forecaster.forecasters_.head()\n\n\n\n\n\n\n\n\nforecasters\n\n\n\n\n0\nNaiveForecaster(window_length=1)\n\n\n1\nNaiveForecaster(window_length=1)\n\n\n2\nNaiveForecaster(window_length=1)\n\n\n3\nNaiveForecaster(window_length=1)\n\n\n4\nNaiveForecaster(window_length=1)\n\n\n\n\n\n\n\nÉ dificil explicar o quanto isso é extremamente útil para código limpo e prototipagem rápida. Foi um dos motivos que me levaram a usar o sktime.",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dados em painel (multi-series)</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/panel_data.html#métricas",
    "href": "content/pt/part2/panel_data.html#métricas",
    "title": "8  Dados em painel (multi-series)",
    "section": "8.3 Métricas",
    "text": "8.3 Métricas\nAgora que temos várias séries, precisamos explicar como calcular métricas de avaliação. O sktime oferece duas opções para isso, como argumentos na criação da métrica:\n\nmultilevel=\"uniform_average_time\" para calcular a média das séries temporais no painel.\nmultilevel=\"raw_values\" para obter o erro por série.\n\n\nfrom sktime.performance_metrics.forecasting import MeanSquaredScaledError\n\nmetric = MeanSquaredScaledError(multilevel=\"uniform_average_time\")\n\n\nmetric(y_true=y_test, y_pred=y_pred_naive, y_train=y_train)\n\nnp.float64(19.047949908747597)\n\n\nNa prática, as métricas que a sua aplicação exige podem ser diferentes. Por exemplo, as séries temporais podem ter diferentes importâncias, e você pode querer ponderar as métricas de acordo.\nPara isso, é possível criar uma métrica customizada no sktime, mas não entraremos nesse mérito aqui.",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dados em painel (multi-series)</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/panel_data.html#modelos-globais-de-machine-learning",
    "href": "content/pt/part2/panel_data.html#modelos-globais-de-machine-learning",
    "title": "8  Dados em painel (multi-series)",
    "section": "8.4 Modelos globais de Machine Learning",
    "text": "8.4 Modelos globais de Machine Learning\nQuando vimos como usar modelos de Machine Learning para forecasting, já mencionamos como é necessário traduzir o problema de séries temporais para um problema de regressão tradicional.\nNo caso de dados em painel, também podemos usar essa abordagem, mas agora aproveitando todas as séries temporais para treinar um único modelo global.\n\nAbaixo, vamos comparar um LightGBM global com um local. Veremos o seguinte: o modelo local é melhor que o modelo global, se não processarmos os dados corretamente para o modelo global aproveitar as similaridades entre as séries!\n\nfrom tsbook.forecasting.reduction import ReductionForecaster\nfrom lightgbm import LGBMRegressor\n\nglobal_forecaster1 = ReductionForecaster(\n    LGBMRegressor(n_estimators=100, verbose=-1, random_state=42),\n    window_length=30,\n)\n\nglobal_forecaster1.fit(y_train, X_train)\n\nReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                    window_length=30)Please rerun this cell to show the HTML repr or trust the notebook.ReductionForecasterReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                    window_length=30)estimator: LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)\n\n\n\ny_pred_global1 = global_forecaster1.predict(fh=fh, X=X_test)\n\n\nfig, ax = plt.subplots(figsize=(10, 4))\ny_train.loc[10, \"sales\"].plot(ax=ax, label=\"Treino\")\ny_test.loc[10, \"sales\"].plot(ax=ax, label=\"Teste\")\ny_pred_global1.loc[10, \"sales\"].plot(ax=ax, label=\"Global 1\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nPara forçar que um modelo global funcione como um modelo local, podemos usar ForecastByLevel, que cria um modelo separado para cada série temporal, mesmo quando o estimador suporta dados em painel.\n\nfrom sktime.forecasting.compose import ForecastByLevel\n\nlocal_forecaster1 = ForecastByLevel(global_forecaster1, groupby=\"local\")\n\nlocal_forecaster1.fit(y_train, X=X_train)\n\nForecastByLevel(forecaster=ReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                                               window_length=30))Please rerun this cell to show the HTML repr or trust the notebook.ForecastByLevel?Documentation for ForecastByLevelForecastByLevel(forecaster=ReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                                               window_length=30))forecaster: ReductionForecasterReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                    window_length=30)estimator: LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)\n\n\n\ny_pred_local1 = local_forecaster1.predict(fh=fh, X=X_test)\n\nerr_global1 = metric(y_true=y_test, y_pred=y_pred_global1, y_train=y_train)\nerr_local1 = metric(y_true=y_test, y_pred=y_pred_local1, y_train=y_train)\n\nerrors = pd.DataFrame(\n    {\n        \"Global (1)\": [err_global1],\n        \"Local (1)\": [err_local1],\n    },\n    index=[\"MSE\"],\n)",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dados em painel (multi-series)</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/panel_data.html#preprocessamento-e-engenharia-de-features",
    "href": "content/pt/part2/panel_data.html#preprocessamento-e-engenharia-de-features",
    "title": "8  Dados em painel (multi-series)",
    "section": "8.5 Preprocessamento e engenharia de features",
    "text": "8.5 Preprocessamento e engenharia de features\nSabemos como preprocessar séries temporais univariadas para melhorar o desempenho dos modelos de ML. Aplicamos da mesma maneira que fizemos anteriormente o Differencer, com objetivo de remover tendências.\n\nfrom sktime.transformations.series.difference import Differencer\n\nglobal_forecaster2 = Differencer() * global_forecaster1\nglobal_forecaster2.fit(y_train, X_train)\n\nTransformedTargetForecaster(steps=[Differencer(),\n                                   ReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                                                       window_length=30)])Please rerun this cell to show the HTML repr or trust the notebook.TransformedTargetForecaster?Documentation for TransformedTargetForecasterTransformedTargetForecaster(steps=[Differencer(),\n                                   ReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                                                       window_length=30)])Differencer?Documentation for DifferencerDifferencer()ReductionForecasterReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                    window_length=30)estimator: LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)\n\n\n\ny_pred_global2 = global_forecaster2.predict(fh=fh, X=X_test)\nmetric_global2 = metric(y_true=y_test, y_pred=y_pred_global2, y_train=y_train)\n\nE agora sua versão local:\n\nlocal_forecaster2 = ForecastByLevel(global_forecaster2, groupby=\"local\")\nlocal_forecaster2.fit(y_train, X=X_train)\n\ny_pred_local2 = local_forecaster2.predict(fh=fh, X=X_test)\nmetric_local2 = metric(y_true=y_test, y_pred=y_pred_local2, y_train=y_train)\n\nAgora, podemos comparar:\n\nerrors[\"Global (2)\"] = metric_global2\nerrors[\"Local (2)\"] = metric_local2\n\nerrors\n\n\n\n\n\n\n\n\nGlobal (1)\nLocal (1)\nGlobal (2)\nLocal (2)\n\n\n\n\nMSE\n34.451879\n23.191404\n26.580076\n57.205596\n\n\n\n\n\n\n\nNote como já superamos o modelo global incial. Isso é para destacar que é essencial realizar um bom preprocessamento e engenharia de features para que modelos de Machine Learning tenham bom desempenho em dados em painel.\n\n8.5.1 Normalização por janela\nAgora, vamos usar a normalização por janela, que é especialmente útil em dados em painel, onde as séries podem ter diferentes escalas.\n\nglobal_forecaster3 = global_forecaster1.clone().set_params(\n    normalization_strategy=\"divide_mean\"\n)\n\nglobal_forecaster3.fit(y_train, X_train)\n\nReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                    normalization_strategy='divide_mean', window_length=30)Please rerun this cell to show the HTML repr or trust the notebook.ReductionForecasterReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                    normalization_strategy='divide_mean', window_length=30)estimator: LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)\n\n\n\n# Predict\ny_pred_global3 = global_forecaster3.predict(fh=fh, X=X_test)\n\n# Métrica\nmetric_global3 = metric(y_true=y_test, y_pred=y_pred_global3, y_train=y_train)\n\nerrors[\"Global 3 (window norm)\"] = metric_global3\n\ndisplay(errors)\n\n\n\n\n\n\n\n\nGlobal (1)\nLocal (1)\nGlobal (2)\nLocal (2)\nGlobal 3 (window norm)\n\n\n\n\nMSE\n34.451879\n23.191404\n26.580076\n57.205596\n16.445518\n\n\n\n\n\n\n\nVemos que resultados são ainda melhores!\n\n\n8.5.2 Pipelines de features exógenas\nPodemos ajudar o modelo a capturar sazonalidades adicionando features de Fourier como features exógenas.\nUsamos ** para criar um pipeline aplicado sobre as features exógenas:\n\nfrom sktime.transformations.series.fourier import FourierFeatures\n\nfourier_features = FourierFeatures(\n    sp_list=[365.25, 365.25 / 12], fourier_terms_list=[1, 1], freq=\"D\"\n)\n\nglobal_forecaster4 = fourier_features**global_forecaster3\nglobal_forecaster4.fit(y_train, X_train)\n\nForecastingPipeline(steps=[FourierFeatures(fourier_terms_list=[1, 1], freq='D',\n                                           sp_list=[365.25, 30.4375]),\n                           ReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                                               normalization_strategy='divide_mean',\n                                               window_length=30)])Please rerun this cell to show the HTML repr or trust the notebook.ForecastingPipeline?Documentation for ForecastingPipelineForecastingPipeline(steps=[FourierFeatures(fourier_terms_list=[1, 1], freq='D',\n                                           sp_list=[365.25, 30.4375]),\n                           ReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                                               normalization_strategy='divide_mean',\n                                               window_length=30)])FourierFeatures?Documentation for FourierFeaturesFourierFeatures(fourier_terms_list=[1, 1], freq='D', sp_list=[365.25, 30.4375])ReductionForecasterReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                    normalization_strategy='divide_mean', window_length=30)estimator: LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)\n\n\n\ny_pred_global4 = global_forecaster4.predict(fh=fh, X=X_test)\nmetric_global4 = metric(y_true=y_test, y_pred=y_pred_global4, y_train=y_train)\n\nerrors[\"Global 4 (fourier)\"] = metric_global4\nerrors\n\n\n\n\n\n\n\n\nGlobal (1)\nLocal (1)\nGlobal (2)\nLocal (2)\nGlobal 3 (window norm)\nGlobal 4 (fourier)\n\n\n\n\nMSE\n34.451879\n23.191404\n26.580076\n57.205596\n16.445518\n15.749969",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dados em painel (multi-series)</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/panel_data.html#agrupamento-modelos-globais",
    "href": "content/pt/part2/panel_data.html#agrupamento-modelos-globais",
    "title": "8  Dados em painel (multi-series)",
    "section": "8.6 Agrupamento + Modelos globais",
    "text": "8.6 Agrupamento + Modelos globais\nUma técnica muito adotada é fazer modelos globais por clusters de séries temporais similares.\nUma maneira de categorizar é usando ADI (Average Demand Interval) e CV² (squared Coefficient of Variation). O componente ADI é calculado como o percentual de períodos com demanda (y&gt;0), e \\(CV^2\\) é o quadrado do coeficiente de variação das demandas positivas.\n\n\n\n\n\n\n\n\n\n\nCategoria\nADI\nCV²\nPadrão típico\nExemplos\n\n\n\n\nSuave (Smooth)\n≤ 1,32\n≤ 0,49\nDemanda contínua e estável\nItens de consumo diário, alimentos\n\n\nErrática (Erratic)\n≤ 1,32\n&gt; 0,49\nDemanda contínua, porém muito variável\nModa, eletrônicos\n\n\nIntermitente (Intermittent)\n&gt; 1,32\n≤ 0,49\nMuitos períodos sem venda, mas valores estáveis quando ocorre\nPeças de reposição, ferramentas\n\n\nIrregular (Lumpy)\n&gt; 1,32\n&gt; 0,49\nMuitos períodos com zero e valores muito variáveis quando há demanda\nEquipamentos caros, sobressalentes grandes\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom sktime.forecasting.compose import GroupbyCategoryForecaster\nfrom sktime.transformations.series.adi_cv import ADICVTransformer\n\n# TODO: customize yours!\ngroup_forecaster = GroupbyCategoryForecaster(\n    forecasters =\n        {\"smooth\": global_forecaster3.clone(),\n        \"erratic\": global_forecaster3.clone(),\n        \"intermittent\": global_forecaster3.clone(),\n        \"lumpy\": global_forecaster3.clone(),\n        },\n    transformer=ADICVTransformer(features=[\"class\"],))\n\n\ngroup_forecaster.fit(y_train, X_train)\n\nGroupbyCategoryForecaster(forecasters={'erratic': ReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                                                                      normalization_strategy='divide_mean',\n                                                                      window_length=30),\n                                       'intermittent': ReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                                                                           normalization_strategy='divide_mean',\n                                                                           window_length=30),\n                                       'lumpy': ReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                                                                    normalization_strategy='divide_mean',\n                                                                    window_length=30),\n                                       'smooth': ReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                                                                     normalization_strategy='divide_mean',\n                                                                     window_length=30)},\n                          transformer=ADICVTransformer(features=['class']))Please rerun this cell to show the HTML repr or trust the notebook.GroupbyCategoryForecaster?Documentation for GroupbyCategoryForecasterGroupbyCategoryForecaster(forecasters={'erratic': ReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                                                                      normalization_strategy='divide_mean',\n                                                                      window_length=30),\n                                       'intermittent': ReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                                                                           normalization_strategy='divide_mean',\n                                                                           window_length=30),\n                                       'lumpy': ReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                                                                    normalization_strategy='divide_mean',\n                                                                    window_length=30),\n                                       'smooth': ReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                                                                     normalization_strategy='divide_mean',\n                                                                     window_length=30)},\n                          transformer=ADICVTransformer(features=['class']))ADICVTransformerADICVTransformer(features=['class'])ADICVTransformer?Documentation for ADICVTransformerADICVTransformer(features=['class'])smoothReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                    normalization_strategy='divide_mean', window_length=30)estimator: LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)erraticReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                    normalization_strategy='divide_mean', window_length=30)estimator: LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)intermittentReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                    normalization_strategy='divide_mean', window_length=30)estimator: LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)lumpyReductionForecaster(estimator=LGBMRegressor(random_state=42, verbose=-1),\n                    normalization_strategy='divide_mean', window_length=30)estimator: LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)LGBMRegressorLGBMRegressor(random_state=42, verbose=-1)fallback_forecasterNoneNoneNone\n\n\n\ny_pred_group = group_forecaster.predict(fh=fh, X=X_test)\nmetric_group = metric(y_true=y_test, y_pred=y_pred_group, y_train=y_train)\n\nmetric_group\n\nnp.float64(46.754957705810234)\n\n\nAlthough it did not perform better than the best global model in this synthetic example, in real-world scenarios this approach can be very effective, particularly when there are large samples for each category, allowing the model to learn specific patterns for each group of series.\nIn addition, this can be useful when there are computation constraints, as training multiple smaller models for each cluster can be more efficient than training a single large global model.",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dados em painel (multi-series)</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/panel_data.html#resumo",
    "href": "content/pt/part2/panel_data.html#resumo",
    "title": "8  Dados em painel (multi-series)",
    "section": "8.7 Resumo",
    "text": "8.7 Resumo\nAqui, vimos como trabalhar com dados em painel (multi-series) usando o sktime. Vimos, especialmente, como criar modelos globais de Machine Learning que aproveitam as similaridades entre as séries para melhorar o desempenho das previsões. Também destacamos a importância do preprocessamento e da engenharia de features para obter bons resultados com esses modelos.\nPara uma análise mais aprofundada, recomendo o artigo de (Montero-Manso and Hyndman 2021), que discute princípios para forecasting em dados em painel usando modelos globais de Machine Learning.\n\n\n\n\nMakridakis, Spyros, Evangelos Spiliotis, and Vassilios Assimakopoulos. 2022. “M5 Accuracy Competition: Results, Findings, and Conclusions.” International Journal of Forecasting 38 (4): 1346–64.\n\n\nMontero-Manso, Pablo, and Rob J Hyndman. 2021. “Principles and Algorithms for Forecasting Groups of Time Series: Locality and Globality.” International Journal of Forecasting 37 (4): 1632–53.",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dados em painel (multi-series)</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/hierarchical_forecasting.html",
    "href": "content/pt/part2/hierarchical_forecasting.html",
    "title": "9  Forecasting Hierárquico",
    "section": "",
    "text": "9.1 Carregando dados\nMuitas vezes, não apenas temos múltiplas séries temporais, mas essas séries também estão organizadas em uma hierarquia. Por exemplo, vendas de produtos podem ser organizadas por SKU, categoria, departamento e total da loja.\nVamos usar o mesmo dataset sintético, mas agora com uma hierarquia de produtos.\nAo mesmo tempo que dados hierarárquicos são interessantes pois nos trazem mais informação, eles também trazem desafios adicionais. Imagine que queremos prever as vendas futuras de cada produto. Se fizermos previsões independetes para cada produto, não há garantia que a soma das previsões dos produtos será igual à previsão do total da loja. Isso é chamado de incoerência nas previsões hierárquicas. O processo de ajustar as previsões para garantir coerência é chamado de reconciliação.\nVamos usar os dados sintéticos, agora com sua versao hierárquica.\nfrom tsbook.datasets.retail import SyntheticRetail\n\ndataset = SyntheticRetail(\"hierarchical\")\ny_train, X_train, y_test, X_test = dataset.load(\"y_train\", \"X_train\", \"y_test\", \"X_test\")",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forecasting Hierárquico</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/hierarchical_forecasting.html#uso-de-pandas-e-dados-hierárquicos",
    "href": "content/pt/part2/hierarchical_forecasting.html#uso-de-pandas-e-dados-hierárquicos",
    "title": "9  Forecasting Hierárquico",
    "section": "9.2 Uso de pandas e dados hierárquicos",
    "text": "9.2 Uso de pandas e dados hierárquicos\nAgora, os dataframes possuem mais de 2 ou mais índices, representando a hierarquia.\n\ny_train\n\n\n\n\n\n\n\n\n\n\nsales\n\n\ngroup_id\nsku_id\ndate\n\n\n\n\n\n-1\n20\n2020-01-01\n0\n\n\n2020-01-02\n0\n\n\n2020-01-03\n0\n\n\n2020-01-04\n0\n\n\n2020-01-05\n2\n\n\n...\n...\n...\n...\n\n\n__total\n__total\n2024-07-01\n2002\n\n\n2024-07-02\n1617\n\n\n2024-07-03\n1917\n\n\n2024-07-04\n2383\n\n\n2024-07-05\n2463\n\n\n\n\n51088 rows × 1 columns\n\n\n\nPara obter o número de pontos de série únicos (séries temporais individuais), podemos fazer o seguinte:\n\ny_train.index.droplevel(-1).nunique()\n\n31\n\n\nNote que existem algumas séries com um identificador __total. Esse identificador representa o total para aquele nível da hierarquia. Por exemplo, se o id completo é (-1, \"__total\"), isso representa o total do grupo -1.\n\ny_train.loc[(-1, \"__total\")].head()\n\n\n\n\n\n\n\n\nsales\n\n\ndate\n\n\n\n\n\n2020-01-01\n4\n\n\n2020-01-02\n2\n\n\n2020-01-03\n3\n\n\n2020-01-04\n14\n\n\n2020-01-05\n16\n\n\n\n\n\n\n\nO total de todas as séries é representado por (\"__total\", \"__total\").\n\ny_train.loc[(\"__total\", \"__total\")]\n\n\n\n\n\n\n\n\nsales\n\n\ndate\n\n\n\n\n\n2020-01-01\n24\n\n\n2020-01-02\n19\n\n\n2020-01-03\n14\n\n\n2020-01-04\n23\n\n\n2020-01-05\n23\n\n\n...\n...\n\n\n2024-07-01\n2002\n\n\n2024-07-02\n1617\n\n\n2024-07-03\n1917\n\n\n2024-07-04\n2383\n\n\n2024-07-05\n2463\n\n\n\n\n1648 rows × 1 columns\n\n\n\nPara contabilizar o número de séries temporais individuais, podemos fazer o seguinte:\n\ny_train.index.droplevel(-1).nunique()\n\n31",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forecasting Hierárquico</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/hierarchical_forecasting.html#previsão-sem-reconciliação",
    "href": "content/pt/part2/hierarchical_forecasting.html#previsão-sem-reconciliação",
    "title": "9  Forecasting Hierárquico",
    "section": "9.3 Previsão sem reconciliação",
    "text": "9.3 Previsão sem reconciliação\nVamos fazer uma previsão e entender o problema da incoerência.\n\nfh = y_test.index.get_level_values(-1).unique()\n\n\nfrom tsbook.forecasting.reduction import ReductionForecaster\nfrom lightgbm import LGBMRegressor\n\nforecaster = ReductionForecaster(\n    LGBMRegressor(n_estimators=100, verbose=-1, objective=\"tweedie\", random_state=42),\n    window_length=30,\n    normalization_strategy=\"divide_mean\",\n)\nforecaster.fit(y_train, X=X_train)\ny_pred = forecaster.predict(fh, X=X_test)\n\nPara somar as previsões de baixo para cima, podemos usar o transformador Aggregator. Vamos ver que, quando somarmos as previsões das séries filhas, o resultado não é igual à previsão da série total.\n\nfrom sktime.transformations.hierarchical.aggregate import Aggregator\n\nAggregator().fit_transform(y_pred) - y_pred\n\n\n\n\n\n\n\n\n\n\nsales\n\n\ngroup_id\nsku_id\ndate\n\n\n\n\n\n-1\n20\n2024-07-06\n0.000000\n\n\n2024-07-07\n0.000000\n\n\n2024-07-08\n0.000000\n\n\n2024-07-09\n0.000000\n\n\n2024-07-10\n0.000000\n\n\n...\n...\n...\n...\n\n\n__total\n__total\n2024-12-28\n-303.956496\n\n\n2024-12-29\n276.995900\n\n\n2024-12-30\n-189.336243\n\n\n2024-12-31\n415.699469\n\n\n2025-01-01\n-148.407308\n\n\n\n\n5580 rows × 1 columns\n\n\n\nExiste uma diferença… ou seja, os valores não batem. Imagine o impacto de levar previsões incoerentes para a tomada de decisão em uma empresa? A raiz do problema é que temos mais modelos que graus de liberdade. Para ilustrar, suponha que temos 3 séries: \\(A\\), \\(B\\) e \\(C\\), onde:\n\\[\nC(t) = A(t) + B(t)\n\\]\nAqui, temos 3 séries, mas apenas 2 graus de liberdade, pois \\(C\\) é completamente determinado por \\(A\\) e \\(B\\). Se fizermos previsões independentes para \\(A\\), \\(B\\) e \\(C\\), não há garantia de que a relação acima será mantida nas previsões.",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forecasting Hierárquico</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/hierarchical_forecasting.html#reconciliação-de-previsões-hierárquicas",
    "href": "content/pt/part2/hierarchical_forecasting.html#reconciliação-de-previsões-hierárquicas",
    "title": "9  Forecasting Hierárquico",
    "section": "9.4 Reconciliação de previsões hierárquicas",
    "text": "9.4 Reconciliação de previsões hierárquicas\n\nExistem diferentes métodos para reconciliar previsões em séries temporais hierárquicas. Não existe uma solução única, e o melhor método depende dos dados e do contexto.",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forecasting Hierárquico</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/hierarchical_forecasting.html#bottom-up",
    "href": "content/pt/part2/hierarchical_forecasting.html#bottom-up",
    "title": "9  Forecasting Hierárquico",
    "section": "9.5 Bottom-up",
    "text": "9.5 Bottom-up\nA maneira mais simples de reconcialiar previsões hierárquicas é a abordagem bottom-up. Nessa abordagem, fazemos previsões apenas para as séries mais baixas na hierarquia (as séries filhas) e depois somamos essas previsões para obter as previsões das séries superiores (as séries pais).\n\nLados positivos:\n\nSimplicidade: fácil de entender e implementar.\nCoerência garantida: a soma das previsões das séries filhas sempre será igual à previsão da série pai.\nSérias filhas podem capturar detalhes específicos que podem ser perdidos em níveis superiores.\n\nNo entanto, essa abordagem também tem desvantagens: é sucetível ao ruído nas séries filhas, e se as séries filhas tiverem pouca informação, as previsões podem ser ruins. Por exemplo, muitos zeros nas séries de níveis baixos pode levar a previsões ruins a niveis agregados.\n\nfrom sktime.transformations.hierarchical.reconcile import BottomUpReconciler\n\nbottom_up = BottomUpReconciler() * forecaster\nbottom_up.fit(y_train)\n\ny_pred_bottomup = bottom_up.predict(fh=fh)\n\nAgora vemos que as previsões são coerentes:\n\nAggregator().fit_transform(y_pred_bottomup) - y_pred_bottomup\n\n\n\n\n\n\n\n\n\n\nsales\n\n\ngroup_id\nsku_id\ndate\n\n\n\n\n\n-1\n20\n2024-07-06\n0.0\n\n\n2024-07-07\n0.0\n\n\n2024-07-08\n0.0\n\n\n2024-07-09\n0.0\n\n\n2024-07-10\n0.0\n\n\n...\n...\n...\n...\n\n\n__total\n__total\n2024-12-28\n0.0\n\n\n2024-12-29\n0.0\n\n\n2024-12-30\n0.0\n\n\n2024-12-31\n0.0\n\n\n2025-01-01\n0.0\n\n\n\n\n5580 rows × 1 columns",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forecasting Hierárquico</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/hierarchical_forecasting.html#top-down-forecast-proportions",
    "href": "content/pt/part2/hierarchical_forecasting.html#top-down-forecast-proportions",
    "title": "9  Forecasting Hierárquico",
    "section": "9.6 Top-down (forecast proportions)",
    "text": "9.6 Top-down (forecast proportions)\nOutra abordagem é a top-down. Nessa abordagem, fazemos previsões apenas para as séries superiores na hierarquia (as séries pais) e depois distribuímos essas previsões para as séries filhas com base em proporções previstas.\nSuponha que temos a seguinte hierarquia \\(C(t) = A(t) + B(t)\\). Considere \\(\\hat{C}(t)\\), \\(\\hat{A}(t)\\) e \\(\\hat{B}(t)\\) como as previsões para \\(C\\), \\(A\\) e \\(B\\), respectivamente. Na abordagem top-down, faríamos o seguinte:\n\nPrever \\(\\hat{C}(t)\\), \\(\\hat{A}(t)\\) e \\(\\hat{B}(t)\\) independentemente.\nCalcular as proporções previstas para os níveis mais baixos: \\[\np_A(t) = \\frac{\\hat{A}(t)}{\\hat{A}(t) + \\hat{B}(t)}\n\\]\n\n\\[\np_B(t) = \\frac{\\hat{B}(t)}{\\hat{A}(t) + \\hat{B}(t)}\n\\]\n\nDistribuir a previsão de \\(C\\) para \\(A\\) e \\(B\\) usando essas proporções: \\[\n\\tilde{A}(t) = p_A(t) \\cdot \\hat{C}(t)\n\\]\n\n\\[\n\\tilde{B}(t) = p_B(t) \\cdot \\hat{C}(t)\n\\]\nEssa abordagem é capaz de usufruir da qualidade do forecast total, e ainda consegue distribuir para as séries filhas baseadas no histórico.\n\nO que chamam de “Proporções históricas” é equivalente a esse método, mas com um modelo Naive para prever as proporções.\nEsse método pode ser bom quando o forecast total é de boa qualidade. No entanto, dependemos profundamente da qualidade do forecast total e das proporções.\n\nfrom sktime.transformations.hierarchical.reconcile import TopdownReconciler\n\ntop_down_fcst = TopdownReconciler() * forecaster\ntop_down_fcst.fit(y_train)\n\ny_pred_topdown = top_down_fcst.predict(fh=fh)",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forecasting Hierárquico</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/hierarchical_forecasting.html#reconciliação-ótima",
    "href": "content/pt/part2/hierarchical_forecasting.html#reconciliação-ótima",
    "title": "9  Forecasting Hierárquico",
    "section": "9.7 Reconciliação ótima",
    "text": "9.7 Reconciliação ótima\nExiste uma abordagem mais sofisticada, com uma intuição geométrica interessante. A ideia é ajustar as previsões iniciais para que elas satisfaçam as restrições de soma da hierarquia. Por exemplo, para a hierarquia \\(C(t) = A(t) + B(t)\\), queremos garantir que:\n\\[\n\\hat{C}(t) = \\hat{A}(t) + \\hat{B}(t)\n\\]\nSe consideramos nosso espaço 3D de observações \\((\\hat{A}, \\hat{B}, \\hat{C})\\), a condição acima é satisfeita para um plano 2D nesse universo.\n\nPodemos então projetar nossas previsões iniciais nesse plano para obter previsões coerentes. Essa projeção pode ser feita de várias maneiras, levando a diferentes métodos de reconciliação ótima. Os métodos levam o nome “OLS” pois a projeção é feita minimizando o erro quadrático (Ordinary Least Squares).\n\nOLS : projetar ortogonalmente todas as previsões base na espaço de reconciliação, tratando todas as séries igualmente.\nWeighted OLS: projetar obliquamente, ou seja, considerando pesos diferentes para cada série, permitindo dar mais importância a certas séries na reconciliação. A projeção não faz mais uma perpendicular, mas sim uma oblíqua.\nMinimum trace (MinT): use a matriz de covariância do erro para encontrar as previsões reconciliadas ótimas. Chamado de “ótimo”.\n\nPara a reconciliação ótima com OLS, podemos usar o OptimalReconciler do sktime:\n\nfrom sktime.transformations.hierarchical.reconcile import OptimalReconciler\n\noptimal = OptimalReconciler(\"ols\") * forecaster\noptimal.fit(y_train)\ny_pred_optimal = optimal.predict(fh=fh)\n\n\n\nCode\nfrom sktime.utils.plotting import plot_series\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n\nidx = y_train.index.droplevel(-1).unique()[10]\n\nplot_series(\n    y_train.loc[idx,],\n    y_test.loc[idx,],\n    y_pred.loc[idx,],\n    y_pred_optimal.loc[idx,],\n    labels=[\"Train\", \"Test\", \"Predicted (sem reconciliação)\", \"Predicted (ótimo)\"],\n)\nplt.xlim(pd.to_datetime(\"2024-05-01\"), None)\nplt.show()\n\n\n\n\n\n\n\n\n\nPara reconciliações ótimas (que usam a covariância do erro), podemos usar o ReconcilerForecaster do sktime, que internamente já faz o cálculo da covariância do erro:\n\nfrom sktime.forecasting.reconcile import ReconcilerForecaster\n\n\nmint_forecaster = ReconcilerForecaster(\n    forecaster=forecaster,\n    method=\"mint_shrink\")\n\nmint_forecaster.fit(y_train)\ny_pred_mint = mint_forecaster.predict(fh=fh)",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forecasting Hierárquico</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/hierarchical_forecasting.html#comparando-resultados",
    "href": "content/pt/part2/hierarchical_forecasting.html#comparando-resultados",
    "title": "9  Forecasting Hierárquico",
    "section": "9.8 Comparando resultados",
    "text": "9.8 Comparando resultados\n\nfrom sktime.performance_metrics.forecasting import MeanSquaredScaledError\n\nmetric = MeanSquaredScaledError(multilevel=\"uniform_average_time\")\n\npd.DataFrame(\n    {\n        \"Baseline\": metric(y_test, y_pred, y_train=y_train),\n        \"BottomUpReconciler\": metric(y_test, y_pred_bottomup, y_train=y_train),\n        \"TopDownReconciler\": metric(y_test, y_pred_topdown, y_train=y_train),\n        \"OptimalReconciler (ols)\": metric(y_test, y_pred_optimal, y_train=y_train),\n        \"Mint Reconciler\": metric(y_test, y_pred_mint, y_train=y_train),\n    },\n    index=[\"Mean Absolute Squared Error\"],\n)\n\n\n\n\n\n\n\n\nBaseline\nBottomUpReconciler\nTopDownReconciler\nOptimalReconciler (ols)\nMint Reconciler\n\n\n\n\nMean Absolute Squared Error\n76.656003\n22.363895\n96.793563\n95.197245\n95.599564",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forecasting Hierárquico</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/deep_learning.html",
    "href": "content/pt/part2/deep_learning.html",
    "title": "10  Modelos de deep learning e zero-shot forecasting",
    "section": "",
    "text": "10.1 N-Beats\nAlém de modelos de ML simples, também podemos usar modelos de deep learning para forecasting. Podemos com certeza usar uma rede neural simples como um regressor, assim como fizemos com os modelos de ML tradicionais. No entanto, existem alguns modelos com arquiteturas específicas para forecasting de séries temporais. Por exemplo, o N-BEATS é um modelo de deep learning que pode ser usado para forecasting.\nN-BEATS é um modelo de séries temporais totalmente baseado em camadas densas (MLP)—nada de RNN/LSTM nem convolução. Ele pega uma janela do passado e entrega diretamente a previsão do futuro, aprendendo padrões como tendência e sazonalidade de forma pura, só com perceptrons.\nO N-BEATS usa bases para construir sinais interpretáveis:\nAssim, internamente, ele determina os coeficientes das funções base para modelar a série temporal, baseado no histórico observado, fazendo uma espécie de meta-aprendizado interno.\nOs blocos são empilhados e executados de forma sucessiva. Pense numa fila de especialistas olhando a mesma janela do passado:",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Modelos de deep learning e zero-shot forecasting</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/deep_learning.html#n-beats",
    "href": "content/pt/part2/deep_learning.html#n-beats",
    "title": "10  Modelos de deep learning e zero-shot forecasting",
    "section": "",
    "text": "Base de tendência: combina funções polinomiais (captura subidas/descidas suaves).\nBase sazonal: combina senos/cossenos (captura repetições periódicas).\nBase genérica: aprende formas livres (sem pressupor forma analítica).\n\n\n\n\nCada um explica a sua parte do que viu (remove do passado o que já foi entendido = backcast), e propõe um pedaço da previsão (seu forecast).\nO que não foi explicado segue para o próximo especialista. No final, a previsão é a soma do que cada um sugeriu.\n\n\n\n10.1.1 Pytorch Forecasting\nO Sktime nao é uma biblioteca especializada em deep learning, mas sim uma API uniforme que provê acesso aos mais diversos algoritmos.\nLogo, também provemos acesso a bibliotecas especializadas em deep learning, como o Pytorch Forecasting, que implementa o N-BEATS.\nAqui, temos que definir os hiperparâmetros do modelo, como o número de blocos, o tamanho do contexto (janela de entrada), e o número de coeficientes para as funcões de base.\n\nfrom sktime.forecasting.pytorchforecasting import PytorchForecastingNBeats\nfrom pytorch_forecasting.data.encoders import EncoderNormalizer\n\nCONTEXT_LENGTH = 120\nnbeats = PytorchForecastingNBeats(\n    train_to_dataloader_params={\"batch_size\": 256},\n    trainer_params={\"max_epochs\": 1},\n    model_params={\n        \"stack_types\": [\"trend\", \"seasonality\"], # One of the following values: “generic”, “seasonality” or “trend”.\n        \"num_blocks\" : [2,2], # The number of blocks per stack. \n        \"context_length\": CONTEXT_LENGTH, # lookback period\n        \"expansion_coefficient_lengths\" : [2, 5],\n        \"learning_rate\": 1e-3,\n    },\n    dataset_params={\n\n        \"max_encoder_length\": CONTEXT_LENGTH,\n        \"target_normalizer\": EncoderNormalizer()\n    },\n)\n\nnbeats.fit(y_train.astype(float), fh=fh)\n\n💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name            | Type       | Params | Mode \n-------------------------------------------------------\n0 | loss            | MASE       | 0      | train\n1 | logging_metrics | ModuleList | 0      | train\n2 | net_blocks      | ModuleList | 1.4 M  | train\n-------------------------------------------------------\n1.4 M     Trainable params\n0         Non-trainable params\n1.4 M     Total params\n5.484     Total estimated model params size (MB)\n60        Modules in train mode\n0         Modules in eval mode\n\n\n\n\n\n\n\n\n\n\n\n`Trainer.fit` stopped: `max_epochs=1` reached.\n\n\nPytorchForecastingNBeats(dataset_params={'max_encoder_length': 120,\n                                         'target_normalizer': EncoderNormalizer(\n    method='standard',\n    center=True,\n    max_length=None,\n    transformation=None,\n    method_kwargs={}\n)},\n                         model_params={'context_length': 120,\n                                       'expansion_coefficient_lengths': [2, 5],\n                                       'learning_rate': 0.001,\n                                       'num_blocks': [2, 2],\n                                       'stack_types': ['trend', 'seasonality']},\n                         train_to_dataloader_params={'batch_size': 256},\n                         trainer_params={'max_epochs': 1})Please rerun this cell to show the HTML repr or trust the notebook.PytorchForecastingNBeats?Documentation for PytorchForecastingNBeatsPytorchForecastingNBeats(dataset_params={'max_encoder_length': 120,\n                                         'target_normalizer': EncoderNormalizer(\n    method='standard',\n    center=True,\n    max_length=None,\n    transformation=None,\n    method_kwargs={}\n)},\n                         model_params={'context_length': 120,\n                                       'expansion_coefficient_lengths': [2, 5],\n                                       'learning_rate': 0.001,\n                                       'num_blocks': [2, 2],\n                                       'stack_types': ['trend', 'seasonality']},\n                         train_to_dataloader_params={'batch_size': 256},\n                         trainer_params={'max_epochs': 1})\n\n\n\ny_pred_nbeats = nbeats.predict(fh=fh, X=X_test)\n\n/opt/hostedtoolcache/Python/3.11.13/x64/lib/python3.11/site-packages/sktime/forecasting/base/adapters/_pytorchforecasting.py:655: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  _y.fillna(0, inplace=True)\n💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n\n\nfrom sktime.performance_metrics.forecasting import MeanSquaredScaledError\n\nmetric = MeanSquaredScaledError(multilevel=\"uniform_average_time\")\nmetric(y_true=y_test, y_pred=y_pred_nbeats, y_train=y_train)\n\nnp.float64(16.0982507019409)\n\n\nAgora, podemos visualizar o forecast para uma das séries. Vemos que, mesmo com poucas épocas de treinamento ou tuning, o N-BEATS já consegue capturar a tendência.\n\nfig, ax = plt.subplots(figsize=(10, 4))\ny_train.loc[10].plot(ax=ax, label=\"Train\")\ny_test.loc[10].plot(ax=ax, label=\"Test\")\ny_pred_nbeats.loc[10].plot(ax=ax, label=\"N-BEATS\")\nfig.show()",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Modelos de deep learning e zero-shot forecasting</span>"
    ]
  },
  {
    "objectID": "content/pt/part2/deep_learning.html#zero-shot-forecasting-com-n-beats",
    "href": "content/pt/part2/deep_learning.html#zero-shot-forecasting-com-n-beats",
    "title": "10  Modelos de deep learning e zero-shot forecasting",
    "section": "10.2 Zero-shot forecasting com N-BEATS",
    "text": "10.2 Zero-shot forecasting com N-BEATS\nZero-shot forecasting se refere ao fato de fazer previsão para uma série jamais vista pelo modeo, sem utilizar a série para treinar ou ajustar parâmetros dele.\nAqui, para simular esse cenário, vamos criar uma nova série temporal combinando duas séries do conjunto de treino.\n\nnew_y_train = (y_train.loc[0]**2 + y_train.loc[20]).astype(float)\nnew_y_test = (y_test.loc[0]**2 + y_test.loc[20]).astype(float)\n\n# Plotting the new series\nfig, ax = plt.subplots(figsize=(10, 4))\nnew_y_train[\"sales\"].plot.line(ax=ax, label=\"New Train\")\nnew_y_test[\"sales\"].plot.line(ax=ax, label=\"New Test\")\nfig.show()\n\n\n\n\n\n\n\n\nNa interface atual do sktime, usamos o argumento y do método predict para passar a nova série temporal para o modelo:\n\ny_pred_zeroshot = nbeats.predict(fh=fh, y=new_y_train)\n\n/opt/hostedtoolcache/Python/3.11.13/x64/lib/python3.11/site-packages/sktime/forecasting/base/adapters/_pytorchforecasting.py:655: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  _y.fillna(0, inplace=True)\n💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n\n\nfig, ax = plt.subplots(figsize=(10, 4))\nnew_y_train[\"sales\"].plot.line(ax=ax, label=\"New Train\")\nnew_y_test[\"sales\"].plot.line(ax=ax, label=\"New Test\")\ny_pred_zeroshot[\"sales\"].plot.line(ax=ax, label=\"N-BEATS Zero-shot\")\nplt.legend()\nplt.show()",
    "crumbs": [
      "Part II: Intermediário",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Modelos de deep learning e zero-shot forecasting</span>"
    ]
  },
  {
    "objectID": "content/pt/extra/sktime_custom.html",
    "href": "content/pt/extra/sktime_custom.html",
    "title": "11  Criando modelos customizados com sktime",
    "section": "",
    "text": "11.1 O sistema de tags\nO sktime oferece um ecossistema robusto, mas em cenarios reais frequentemente precisamos ajustar comportamentos, incorporar dados hierarquicos ou adicionar pre-processamentos especificos. Felizmente, o sktime torna relativamente simples a criacao de modelos customizados, desde que sigamos algumas regras.\nAcredito que essa e uma das grandes vantagens da biblioteca: o foco em ser extensivel e customizavel.\nEntre a chamada dos metodos publicos e privados existe uma camada de validacoes e conversões controlada pelas tags. Elas sinalizam ao BaseForecaster e ao BaseTransformer o que precisa ser garantido antes de executar a implementacao customizada.\nAs tags mais importantes para um forecaster podem ser definidas assim:\nCada uma delas indica o que o modelo é capaz de fazer nos seus métodos privados _fit e _predict:\nOs machine-types (mtypes), ou tipos para máquina, são a peça mais crucial nesse sistema.",
    "crumbs": [
      "Part III: Apêndices",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Criando modelos customizados com sktime</span>"
    ]
  },
  {
    "objectID": "content/pt/extra/sktime_custom.html#o-sistema-de-tags",
    "href": "content/pt/extra/sktime_custom.html#o-sistema-de-tags",
    "title": "11  Criando modelos customizados com sktime",
    "section": "",
    "text": "_tags = {\n    \"capability:exogenous\": True,\n    \"requires-fh-in-fit\": False,\n    \"X_inner_mtype\": [\n        \"pd.Series\",\n        \"pd.DataFrame\",\n        \"pd-multiindex\",\n        \"pd_multiindex_hier\",\n    ],\n    \"y_inner_mtype\": [\n        \"pd.Series\",\n        \"pd.DataFrame\",\n        \"pd-multiindex\",\n        \"pd_multiindex_hier\",\n    ]\n}\n\n\ncapability:exogenous: Indica se o modelo suporta variáveis exógenas (X) durante o ajuste e a previsão.\nrequires-fh-in-fit: Indica se o modelo precisa do horizonte de previsão (fh) durante o ajuste. Alguns modelos precisam devido a sua implementação interna.\ny_inner_mtype: Define os tipos de dados aceitos para a variável dependente (y) durante o ajuste e a previsão.\nX_inner_mtype: Define os tipos de dados aceitos para as variáveis exógenas (X) durante o ajuste e a previsão.\n\n\n\n11.1.1 Machine-types disponiveis\nOs mtypes definem qual a estrutura de dados que o modelo aceita como entrada e produz como saída. Os principais mtypes para séries temporais são:\n\nnp.ndarray\npd.Series\npd.DataFrame\npd-multiindex (ideia de painel)\npd_multiindex_hier (dados hierarquicos)\n\nSe o modelo suporta um mtype hierárquico e passamos um dado hierárquico, o dado chegará normalmente ao método privado _fit ou _predict. Caso contrário, o sktime tentará converter o dado para um mtype suportado.\n\n11.1.1.1 Baixando exemplos por mtype\nPara entender melhor cada mtype, podemos baixar exemplos práticos usando a função get_examples do sktime:\n\nfrom sktime.datatypes import get_examples\n\nget_examples(mtype=\"np.ndarray\", as_scitype=\"Series\")[0]\n\narray([[ 1. ],\n       [ 4. ],\n       [ 0.5],\n       [-3. ]])\n\n\n\nget_examples(mtype=\"pd.DataFrame\", as_scitype=\"Series\")[0].head()\n\n\n\n\n\n\n\n\na\n\n\n\n\n0\n1.0\n\n\n1\n4.0\n\n\n2\n0.5\n\n\n3\n-3.0\n\n\n\n\n\n\n\n\nget_examples(mtype=\"pd-multiindex\", as_scitype=\"Panel\")[0].head()\n\n\n\n\n\n\n\n\n\nvar_0\nvar_1\n\n\ninstances\ntimepoints\n\n\n\n\n\n\n0\n0\n1\n4\n\n\n1\n2\n5\n\n\n2\n3\n6\n\n\n1\n0\n1\n4\n\n\n1\n2\n55\n\n\n\n\n\n\n\n\nget_examples(mtype=\"pd_multiindex_hier\", as_scitype=\"Hierarchical\")[0].head()\n\n\n\n\n\n\n\n\n\n\nvar_0\nvar_1\n\n\nfoo\nbar\ntimepoints\n\n\n\n\n\n\na\n0\n0\n1\n4\n\n\n1\n2\n5\n\n\n2\n3\n6\n\n\n1\n0\n1\n4\n\n\n1\n2\n55\n\n\n\n\n\n\n\nAlguns mtypes tem limitações: uma pd.Series simples nao representa problemas hierarquicos, sendo necessario recorrer ao pd_multiindex_hier.\n\n\n11.1.1.2 Exemplo prático\nVamos criar o nosso primeiro esqueleto de forecaster customizado. Para isso, baixamos uma série de exemplo:\n\nfrom sktime.forecasting.base import BaseForecaster\nfrom sktime.utils._testing.series import _make_series\n\ny = _make_series(4)\ny\n\n2000-01-01    2.444364\n2000-01-02    1.000000\n2000-01-03    2.909860\n2000-01-04    3.562910\nFreq: D, dtype: float64\n\n\nNosso protótipo irá apenas printar os dados recebidos no método _fit. O __init__ recebe um dicionário de tags para definir as capacidades do modelo.\n\nclass Logger(BaseForecaster):\n\n    _tags = {\n        \"requires-fh-in-fit\": False,\n    }\n\n    def __init__(self, tags_to_set):\n        self.tags_to_set = tags_to_set\n        super().__init__()\n\n        self.set_tags(**tags_to_set)\n    \n    def _fit(self, y, X=None, fh=None):\n        print(\"Inside fit:\")\n        print(y)\n        return self\n\n\nlogger = Logger(tags_to_set={\"y_inner_mtype\" : [\"pd.Series\"] })\nlogger.fit(y)\n\nInside fit:\n2000-01-01    2.444364\n2000-01-02    1.000000\n2000-01-03    2.909860\n2000-01-04    3.562910\nFreq: D, dtype: float64\n\n\nLogger(tags_to_set={'y_inner_mtype': ['pd.Series']})Please rerun this cell to show the HTML repr or trust the notebook.LoggerLogger(tags_to_set={'y_inner_mtype': ['pd.Series']})\n\n\n\nlogger = Logger(tags_to_set={\"y_inner_mtype\" : [\"np.ndarray\"] })\nlogger.fit(y)\n\nInside fit:\n[[2.44436429]\n [1.        ]\n [2.90985984]\n [3.56291007]]\n\n\nLogger(tags_to_set={'y_inner_mtype': ['np.ndarray']})Please rerun this cell to show the HTML repr or trust the notebook.LoggerLogger(tags_to_set={'y_inner_mtype': ['np.ndarray']})\n\n\n\nlogger = Logger(tags_to_set={\"y_inner_mtype\" : [\"pd.DataFrame\"] })\nlogger.fit(y)\n\nInside fit:\n                   0\n2000-01-01  2.444364\n2000-01-02  1.000000\n2000-01-03  2.909860\n2000-01-04  3.562910\n\n\nLogger(tags_to_set={'y_inner_mtype': ['pd.DataFrame']})Please rerun this cell to show the HTML repr or trust the notebook.LoggerLogger(tags_to_set={'y_inner_mtype': ['pd.DataFrame']})\n\n\n\ntry:\n    logger = Logger(tags_to_set={\"y_inner_mtype\" : [\"pd_multiindex_hier\"] })\n    logger.fit(y)\nexcept ValueError as e:\n    print(e)\n\nError in Logger, no series scitypes supported, likely a bug in estimator: scitypes arg passed to _most_complex_scitype are ['Hierarchical']\n\n\n\ntry:\n    logger = Logger(tags_to_set={\"y_inner_mtype\": [\"pd.DataFrame\", \"pd_multiindex_hier\"]})\n    logger.fit(y)\nexcept ValueError as e:\n    print(e)\n\nInside fit:\n                   0\n2000-01-01  2.444364\n2000-01-02  1.000000\n2000-01-03  2.909860\n2000-01-04  3.562910\n\n\n\n\n11.1.1.3 Input hierárquico\nAgora veremos como o modelo se comporta com dados hierárquicos. Note que, nos casos onde o modelo não suporta dados hierárquicos, o sktime tentará convertê-los para um mtype suportado.\n\nfrom sktime.utils._testing.hierarchical import _make_hierarchical\n\ny = _make_hierarchical((1,2), max_timepoints=4, min_timepoints=2)\ny\n\n\n\n\n\n\n\n\n\n\nc0\n\n\nh0\nh1\ntime\n\n\n\n\n\nh0_0\nh1_0\n2000-01-02\n2.447055\n\n\n2000-01-03\n2.230500\n\n\n2000-01-04\n2.088361\n\n\nh1_1\n2000-01-02\n1.000000\n\n\n2000-01-03\n2.309531\n\n\n2000-01-04\n4.024129\n\n\n\n\n\n\n\n\nlogger = Logger(tags_to_set={\"y_inner_mtype\" : [\"pd.Series\"] })\nlogger.fit(y)\n\nInside fit:\ntime\n2000-01-02    2.447055\n2000-01-03    2.230500\n2000-01-04    2.088361\nFreq: D, dtype: float64\nInside fit:\ntime\n2000-01-02    1.000000\n2000-01-03    2.309531\n2000-01-04    4.024129\nFreq: D, dtype: float64\n\n\nLogger(tags_to_set={'y_inner_mtype': ['pd.Series']})Please rerun this cell to show the HTML repr or trust the notebook.LoggerLogger(tags_to_set={'y_inner_mtype': ['pd.Series']})\n\n\n\nlogger = Logger(tags_to_set={\"y_inner_mtype\" : [\"np.ndarray\"] })\nlogger.fit(y)\n\nInside fit:\n[[2.44705499]\n [2.23050044]\n [2.08836064]]\nInside fit:\n[[1.        ]\n [2.30953112]\n [4.02412876]]\n\n\nLogger(tags_to_set={'y_inner_mtype': ['np.ndarray']})Please rerun this cell to show the HTML repr or trust the notebook.LoggerLogger(tags_to_set={'y_inner_mtype': ['np.ndarray']})\n\n\n\nlogger = Logger(tags_to_set={\"y_inner_mtype\" : [\"pd.DataFrame\"] })\nlogger.fit(y)\n\nInside fit:\n                  c0\ntime                \n2000-01-02  2.447055\n2000-01-03  2.230500\n2000-01-04  2.088361\nInside fit:\n                  c0\ntime                \n2000-01-02  1.000000\n2000-01-03  2.309531\n2000-01-04  4.024129\n\n\nLogger(tags_to_set={'y_inner_mtype': ['pd.DataFrame']})Please rerun this cell to show the HTML repr or trust the notebook.LoggerLogger(tags_to_set={'y_inner_mtype': ['pd.DataFrame']})\n\n\n\ntry:\n    logger = Logger(tags_to_set={\"y_inner_mtype\": [\"pd_multiindex_hier\"]})\n    logger.fit(y)\nexcept ValueError as e:\n    print(e)\n\nInside fit:\n                            c0\nh0   h1   time                \nh0_0 h1_0 2000-01-02  2.447055\n          2000-01-03  2.230500\n          2000-01-04  2.088361\n     h1_1 2000-01-02  1.000000\n          2000-01-03  2.309531\n          2000-01-04  4.024129",
    "crumbs": [
      "Part III: Apêndices",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Criando modelos customizados com sktime</span>"
    ]
  },
  {
    "objectID": "content/pt/extra/sktime_custom.html#criando-um-modelo-naive",
    "href": "content/pt/extra/sktime_custom.html#criando-um-modelo-naive",
    "title": "11  Criando modelos customizados com sktime",
    "section": "11.2 Criando um modelo naive",
    "text": "11.2 Criando um modelo naive\nAgora, vamos implementar um modelo simples de previsão, o CustomNaiveForecaster, que prevê o valor médio dos últimos n pontos da série temporal.\nÉ um exemplo simples, mas que ilustra bem como criar um forecaster customizado com sktime.\n\nfrom tsbook.datasets.retail import SyntheticRetail\n\ndataset = SyntheticRetail(\"panel\")\ny_train, y_test  = dataset.load(\"y_train\", \"y_test\")\ny_train\n\n\n\n\n\n\n\n\n\nsales\n\n\nsku_id\ndate\n\n\n\n\n\n0\n2020-01-01\n0\n\n\n2020-01-02\n0\n\n\n2020-01-03\n0\n\n\n2020-01-04\n0\n\n\n2020-01-05\n0\n\n\n...\n...\n...\n\n\n24\n2024-07-01\n218\n\n\n2024-07-02\n198\n\n\n2024-07-03\n182\n\n\n2024-07-04\n210\n\n\n2024-07-05\n209\n\n\n\n\n41200 rows × 1 columns\n\n\n\n\nfrom sktime.utils.plotting import plot_series\n\nplot_series(\n    y_train.loc[0],\n    y_train.loc[24],\n    labels=[\n        \"SKU 0\",\n        \"SKU 24\",\n    ],\n)\n\n\n\n\n\n\n\n\nAbaixo, implementamos o CustomNaiveForecaster seguindo as regras do sktime (clique para expandir). Em seguida, explicamos passo a passo.\n\n\nCode\nfrom sktime.forecasting.base import BaseForecaster\nimport pandas as pd\n\n\nclass CustomNaiveForecaster(BaseForecaster):\n    \"\"\"\n    A simple naive forecaster\n\n    Parameters\n    ----------\n    n : int\n        Number of past values to use.\n    \"\"\"\n\n    _tags = {\n        \"requires-fh-in-fit\": False,\n        \"y_inner_mtype\": [\n            \"pd.Series\",\n        ],\n    }\n\n    # Add hyperparameters in init!\n    def __init__(self, n=1):\n        # 1. Set hyper-parameters\n        self.n = n\n\n        # 2. Initialize parent class\n        super().__init__()\n\n        # 3. Check hyper-parameters\n        assert self.n &gt; 0, \"n must be greater than 0\"\n\n    def _fit(self, y, X, fh):\n        \"\"\"\n        Fit necessary parameters.\n        \"\"\"\n\n        self.value_ = y.iloc[-self.n :].mean()\n        return self\n\n    def _predict(self, fh, X):\n        \"\"\"\n        Use forecasting horizon and optionally X to predict y\n        \"\"\"\n\n        # During fit, BaseForecaster sets\n        # self.cutoff to the latest cutoff time point\n        index = fh.to_absolute_index(self.cutoff)\n        y_pred = pd.Series(\n            index=index,\n            data=[self.value_ for _ in range(len(index))],\n        )\n        y_pred.name = self._y.name\n\n        return y_pred\n\n    # Veremos mais tarde como usar esse método\n    @classmethod\n    def get_test_params(cls, parameter_set=\"default\"):\n        return [\n            {\"n\": 1},\n            {\"n\": 2},\n        ]\n\n\n\n11.2.1 Definindo o método __init__\nO método __init__ possui 3 etapas:\n\nA definição dos hiperparametros e seus atributos com mesmo nome.\nA chamada do super().__init__() para inicializar a classe pai.\nA validação dos hiperparâmetros.\n\n# Add hyperparameters in init!\ndef __init__(self, n=1):\n    # 1. Set hyper-parameters\n    self.n = n\n\n    # 2. Initialize parent class\n    super().__init__()\n\n    # 3. Check hyper-parameters\n    assert self.n &gt; 0, \"n must be greater than 0\"\nNo caso de algum preprocessamento dos hiperparâmetros no __init__, devemos guardar em uma variável com nome diferente do hiperparâmetro. Por exemplo, se tivéssemos interesse em ter um atributo n diferente do passado no __init__, poderíamos fazer:\nself._n = n + 1\nO self.n funciona como uma digital do modelo, e deve ser exatamente o que foi passado no __init__.\n\n\n11.2.2 Definindo o método _fit\nNo método _fit, devemos implementar a lógica de ajuste do modelo. No nosso caso, calculamos a média dos últimos n valores e armazenamos em self.value_.\nO _ após o nome do atributo indica que é um atributo aprendido durante o ajuste, e será retornado quando chamarmos get_fitted_params().\nNote que podemos supor que y é do tipo definido na tag y_inner_mtype, ou seja, uma pd.Series.\n\n\n11.2.3 Definindo o método _predict\nNo método _predict, implementamos a lógica de previsão. Usamos o horizonte de previsão fh para determinar os índices futuros e retornamos uma série com o valor previsto para cada ponto no horizonte.\nO fh é um objeto do tipo ForecastingHorizon, que possui o método to_absolute_index(cutoff) para converter o horizonte relativo em índices absolutos, considerando o último ponto conhecido (self.cutoff).\nRetornamos um pd.Series com os índices e os valores previstos.\n\n\n11.2.4 Usando o CustomNaiveForecaster\nAgora, já podemos usar o nosso modelo customizado para fazer previsões.\n\ncustom_naive_model = CustomNaiveForecaster()\ncustom_naive_model.fit(y_train)\n\nCustomNaiveForecaster()Please rerun this cell to show the HTML repr or trust the notebook.CustomNaiveForecasterCustomNaiveForecaster()\n\n\nComo passamos um dado hierárquico, o sktime converteu automaticamente para pd.Series, que é o mtype suportado pelo nosso modelo. Os modelos internos, para cada série, ficam disponíveis em forecasters_.\n\ncustom_naive_model.forecasters_\n\n\n\n\n\n\n\n\nforecasters\n\n\n\n\n0\nCustomNaiveForecaster()\n\n\n1\nCustomNaiveForecaster()\n\n\n2\nCustomNaiveForecaster()\n\n\n3\nCustomNaiveForecaster()\n\n\n4\nCustomNaiveForecaster()\n\n\n5\nCustomNaiveForecaster()\n\n\n6\nCustomNaiveForecaster()\n\n\n7\nCustomNaiveForecaster()\n\n\n8\nCustomNaiveForecaster()\n\n\n9\nCustomNaiveForecaster()\n\n\n10\nCustomNaiveForecaster()\n\n\n11\nCustomNaiveForecaster()\n\n\n12\nCustomNaiveForecaster()\n\n\n13\nCustomNaiveForecaster()\n\n\n14\nCustomNaiveForecaster()\n\n\n15\nCustomNaiveForecaster()\n\n\n16\nCustomNaiveForecaster()\n\n\n17\nCustomNaiveForecaster()\n\n\n18\nCustomNaiveForecaster()\n\n\n19\nCustomNaiveForecaster()\n\n\n20\nCustomNaiveForecaster()\n\n\n21\nCustomNaiveForecaster()\n\n\n22\nCustomNaiveForecaster()\n\n\n23\nCustomNaiveForecaster()\n\n\n24\nCustomNaiveForecaster()\n\n\n\n\n\n\n\n\ny_pred = custom_naive_model.predict(fh=y_test.index.get_level_values(-1).unique())\n\nfig, _ = plot_series(\n    y_train.loc[0],\n    y_pred.loc[0],\n    labels=[\n        \"SKU 0\",\n        \"Previsão SKU 0\",\n    ],\n)\nfig.show()",
    "crumbs": [
      "Part III: Apêndices",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Criando modelos customizados com sktime</span>"
    ]
  },
  {
    "objectID": "content/pt/extra/sktime_custom.html#testes-unitários",
    "href": "content/pt/extra/sktime_custom.html#testes-unitários",
    "title": "11  Criando modelos customizados com sktime",
    "section": "11.3 Testes unitários",
    "text": "11.3 Testes unitários\nO sktime também fornece uma funcionalidade que traz testes unitários prontos para validar se o modelo customizado está funcionando corretamente.\nEle usa os hiperparâmetros retornados pelo método get_test_params para criar instâncias do modelo e executar uma série de testes.\n\nfrom sktime.utils.estimator_checks import check_estimator\n\n\ncheck_estimator(CustomNaiveForecaster, tests_to_exclude=[\"test_doctest_examples\"])\n\nAll tests PASSED!\n\n\n{'test_create_test_instances_and_names[CustomNaiveForecaster]': 'PASSED',\n 'test_obj_vs_cls_signature[CustomNaiveForecaster]': 'PASSED',\n 'test_has_common_interface[CustomNaiveForecaster]': 'PASSED',\n 'test_valid_estimator_class_tags[CustomNaiveForecaster]': 'PASSED',\n 'test_set_params[CustomNaiveForecaster-0]': 'PASSED',\n 'test_set_params[CustomNaiveForecaster-1]': 'PASSED',\n 'test_valid_estimator_tags[CustomNaiveForecaster-0]': 'PASSED',\n 'test_valid_estimator_tags[CustomNaiveForecaster-1]': 'PASSED',\n 'test_get_params[CustomNaiveForecaster-0]': 'PASSED',\n 'test_get_params[CustomNaiveForecaster-1]': 'PASSED',\n 'test_no_between_test_case_side_effects[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX-0]': 'PASSED',\n 'test_no_between_test_case_side_effects[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX-1]': 'PASSED',\n 'test_no_between_test_case_side_effects[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX-0]': 'PASSED',\n 'test_no_between_test_case_side_effects[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX-1]': 'PASSED',\n 'test_no_between_test_case_side_effects[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX-0]': 'PASSED',\n 'test_no_between_test_case_side_effects[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX-1]': 'PASSED',\n 'test_no_between_test_case_side_effects[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX-0]': 'PASSED',\n 'test_no_between_test_case_side_effects[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX-1]': 'PASSED',\n 'test_get_test_params[CustomNaiveForecaster]': 'PASSED',\n 'test_no_cross_test_side_effects_part1[CustomNaiveForecaster-0]': 'PASSED',\n 'test_no_cross_test_side_effects_part1[CustomNaiveForecaster-1]': 'PASSED',\n 'test_repr_html[CustomNaiveForecaster-0]': 'PASSED',\n 'test_repr_html[CustomNaiveForecaster-1]': 'PASSED',\n 'test_clone[CustomNaiveForecaster-0]': 'PASSED',\n 'test_clone[CustomNaiveForecaster-1]': 'PASSED',\n 'test_random_tags[CustomNaiveForecaster]': 'PASSED',\n 'test_inheritance[CustomNaiveForecaster]': 'PASSED',\n 'test_repr[CustomNaiveForecaster-0]': 'PASSED',\n 'test_repr[CustomNaiveForecaster-1]': 'PASSED',\n 'test_no_cross_test_side_effects_part2[CustomNaiveForecaster-0]': 'PASSED',\n 'test_no_cross_test_side_effects_part2[CustomNaiveForecaster-1]': 'PASSED',\n 'test_constructor[CustomNaiveForecaster]': 'PASSED',\n 'test_set_params_sklearn[CustomNaiveForecaster]': 'PASSED',\n 'test_get_test_params_coverage[CustomNaiveForecaster]': 'PASSED',\n 'test_create_test_instance[CustomNaiveForecaster]': 'PASSED',\n 'test_estimator_tags[CustomNaiveForecaster]': 'PASSED',\n 'test_non_state_changing_method_contract[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX-predict]': 'PASSED',\n 'test_non_state_changing_method_contract[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX-get_fitted_params]': 'PASSED',\n 'test_non_state_changing_method_contract[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX-predict]': 'PASSED',\n 'test_non_state_changing_method_contract[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX-get_fitted_params]': 'PASSED',\n 'test_non_state_changing_method_contract[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX-predict]': 'PASSED',\n 'test_non_state_changing_method_contract[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX-get_fitted_params]': 'PASSED',\n 'test_non_state_changing_method_contract[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX-predict]': 'PASSED',\n 'test_non_state_changing_method_contract[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX-get_fitted_params]': 'PASSED',\n 'test_save_estimators_to_file[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX-predict]': 'PASSED',\n 'test_save_estimators_to_file[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX-predict]': 'PASSED',\n 'test_save_estimators_to_file[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX-predict]': 'PASSED',\n 'test_save_estimators_to_file[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX-predict]': 'PASSED',\n 'test_fit_does_not_overwrite_hyper_params[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX]': 'PASSED',\n 'test_fit_does_not_overwrite_hyper_params[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX]': 'PASSED',\n 'test_fit_does_not_overwrite_hyper_params[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX]': 'PASSED',\n 'test_fit_does_not_overwrite_hyper_params[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX]': 'PASSED',\n 'test_fit_updates_state[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX]': 'PASSED',\n 'test_fit_updates_state[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX]': 'PASSED',\n 'test_fit_updates_state[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX]': 'PASSED',\n 'test_fit_updates_state[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX]': 'PASSED',\n 'test_multiprocessing_idempotent[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX-predict]': 'PASSED',\n 'test_multiprocessing_idempotent[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX-predict]': 'PASSED',\n 'test_multiprocessing_idempotent[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX-predict]': 'PASSED',\n 'test_multiprocessing_idempotent[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX-predict]': 'PASSED',\n 'test_methods_have_no_side_effects[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX-predict]': 'PASSED',\n 'test_methods_have_no_side_effects[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX-get_fitted_params]': 'PASSED',\n 'test_methods_have_no_side_effects[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX-predict]': 'PASSED',\n 'test_methods_have_no_side_effects[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX-get_fitted_params]': 'PASSED',\n 'test_methods_have_no_side_effects[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX-predict]': 'PASSED',\n 'test_methods_have_no_side_effects[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX-get_fitted_params]': 'PASSED',\n 'test_methods_have_no_side_effects[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX-predict]': 'PASSED',\n 'test_methods_have_no_side_effects[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX-get_fitted_params]': 'PASSED',\n 'test_raises_not_fitted_error[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX-predict]': 'PASSED',\n 'test_raises_not_fitted_error[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX-get_fitted_params]': 'PASSED',\n 'test_raises_not_fitted_error[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX-predict]': 'PASSED',\n 'test_raises_not_fitted_error[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX-get_fitted_params]': 'PASSED',\n 'test_raises_not_fitted_error[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX-predict]': 'PASSED',\n 'test_raises_not_fitted_error[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX-get_fitted_params]': 'PASSED',\n 'test_raises_not_fitted_error[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX-predict]': 'PASSED',\n 'test_raises_not_fitted_error[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX-get_fitted_params]': 'PASSED',\n 'test_dl_constructor_initializes_deeply[CustomNaiveForecaster]': 'PASSED',\n 'test_fit_returns_self[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX]': 'PASSED',\n 'test_fit_returns_self[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX]': 'PASSED',\n 'test_fit_returns_self[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX]': 'PASSED',\n 'test_fit_returns_self[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX]': 'PASSED',\n 'test_persistence_via_pickle[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX-predict]': 'PASSED',\n 'test_persistence_via_pickle[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX-predict]': 'PASSED',\n 'test_persistence_via_pickle[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX-predict]': 'PASSED',\n 'test_persistence_via_pickle[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX-predict]': 'PASSED',\n 'test_fit_idempotent[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX-predict]': 'PASSED',\n 'test_fit_idempotent[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX-predict]': 'PASSED',\n 'test_fit_idempotent[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX-predict]': 'PASSED',\n 'test_fit_idempotent[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX-predict]': 'PASSED',\n 'test_get_fitted_params[CustomNaiveForecaster-0-ForecasterFitPredictUnivariateWithX]': 'PASSED',\n 'test_get_fitted_params[CustomNaiveForecaster-0-ForecasterFitPredictMultivariateNoX]': 'PASSED',\n 'test_get_fitted_params[CustomNaiveForecaster-1-ForecasterFitPredictUnivariateWithX]': 'PASSED',\n 'test_get_fitted_params[CustomNaiveForecaster-1-ForecasterFitPredictMultivariateNoX]': 'PASSED',\n 'test__y_when_refitting[CustomNaiveForecaster-0-y:1cols]': 'PASSED',\n 'test__y_when_refitting[CustomNaiveForecaster-0-y:2cols]': 'PASSED',\n 'test__y_when_refitting[CustomNaiveForecaster-1-y:1cols]': 'PASSED',\n 'test__y_when_refitting[CustomNaiveForecaster-1-y:2cols]': 'PASSED',\n 'test__y_and_cutoff[CustomNaiveForecaster-0-y:1cols]': 'PASSED',\n 'test__y_and_cutoff[CustomNaiveForecaster-0-y:2cols]': 'PASSED',\n 'test__y_and_cutoff[CustomNaiveForecaster-1-y:1cols]': 'PASSED',\n 'test__y_and_cutoff[CustomNaiveForecaster-1-y:2cols]': 'PASSED',\n 'test_fh_not_passed_error_handling[CustomNaiveForecaster-0-y:1cols]': 'PASSED',\n 'test_fh_not_passed_error_handling[CustomNaiveForecaster-0-y:2cols]': 'PASSED',\n 'test_fh_not_passed_error_handling[CustomNaiveForecaster-1-y:1cols]': 'PASSED',\n 'test_fh_not_passed_error_handling[CustomNaiveForecaster-1-y:2cols]': 'PASSED',\n 'test_different_fh_in_fit_and_predict_error_handling[CustomNaiveForecaster-0-y:1cols]': 'PASSED',\n 'test_different_fh_in_fit_and_predict_error_handling[CustomNaiveForecaster-0-y:2cols]': 'PASSED',\n 'test_different_fh_in_fit_and_predict_error_handling[CustomNaiveForecaster-1-y:1cols]': 'PASSED',\n 'test_different_fh_in_fit_and_predict_error_handling[CustomNaiveForecaster-1-y:2cols]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:1cols-fh=1-alpha=0.05-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:1cols-fh=1-alpha=0.05-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:1cols-fh=1-alpha=0.1-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:1cols-fh=1-alpha=0.1-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:1cols-fh=1-alpha=[0.25, 0.75]-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:1cols-fh=1-alpha=[0.25, 0.75]-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-alpha=0.05-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-alpha=0.05-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-alpha=0.1-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-alpha=0.1-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-alpha=[0.25, 0.75]-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-alpha=[0.25, 0.75]-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:2cols-fh=1-alpha=0.05-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:2cols-fh=1-alpha=0.05-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:2cols-fh=1-alpha=0.1-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:2cols-fh=1-alpha=0.1-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:2cols-fh=1-alpha=[0.25, 0.75]-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:2cols-fh=1-alpha=[0.25, 0.75]-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-alpha=0.05-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-alpha=0.05-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-alpha=0.1-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-alpha=0.1-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-alpha=[0.25, 0.75]-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-alpha=[0.25, 0.75]-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:1cols-fh=1-alpha=0.05-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:1cols-fh=1-alpha=0.05-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:1cols-fh=1-alpha=0.1-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:1cols-fh=1-alpha=0.1-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:1cols-fh=1-alpha=[0.25, 0.75]-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:1cols-fh=1-alpha=[0.25, 0.75]-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-alpha=0.05-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-alpha=0.05-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-alpha=0.1-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-alpha=0.1-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-alpha=[0.25, 0.75]-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-alpha=[0.25, 0.75]-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:2cols-fh=1-alpha=0.05-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:2cols-fh=1-alpha=0.05-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:2cols-fh=1-alpha=0.1-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:2cols-fh=1-alpha=0.1-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:2cols-fh=1-alpha=[0.25, 0.75]-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:2cols-fh=1-alpha=[0.25, 0.75]-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-alpha=0.05-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-alpha=0.05-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-alpha=0.1-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-alpha=0.1-1]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-alpha=[0.25, 0.75]-0]': 'PASSED',\n 'test_predict_interval[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-alpha=[0.25, 0.75]-1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:1cols-update_params=True-0-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:1cols-update_params=True-0-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:1cols-update_params=True-1-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:1cols-update_params=True-1-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:1cols-update_params=False-step=1-0-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:1cols-update_params=False-step=1-0-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:1cols-update_params=False-step=1-1-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:1cols-update_params=False-step=1-1-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:1cols-update_params=False-step=5-0-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:1cols-update_params=False-step=5-0-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:1cols-update_params=False-step=5-1-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:1cols-update_params=False-step=5-1-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:2cols-update_params=True-0-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:2cols-update_params=True-0-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:2cols-update_params=True-1-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:2cols-update_params=True-1-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:2cols-update_params=False-step=1-0-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:2cols-update_params=False-step=1-0-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:2cols-update_params=False-step=1-1-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:2cols-update_params=False-step=1-1-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:2cols-update_params=False-step=5-0-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:2cols-update_params=False-step=5-0-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:2cols-update_params=False-step=5-1-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-0-y:2cols-update_params=False-step=5-1-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:1cols-update_params=True-0-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:1cols-update_params=True-0-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:1cols-update_params=True-1-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:1cols-update_params=True-1-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:1cols-update_params=False-step=1-0-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:1cols-update_params=False-step=1-0-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:1cols-update_params=False-step=1-1-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:1cols-update_params=False-step=1-1-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:1cols-update_params=False-step=5-0-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:1cols-update_params=False-step=5-0-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:1cols-update_params=False-step=5-1-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:1cols-update_params=False-step=5-1-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:2cols-update_params=True-0-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:2cols-update_params=True-0-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:2cols-update_params=True-1-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:2cols-update_params=True-1-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:2cols-update_params=False-step=1-0-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:2cols-update_params=False-step=1-0-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:2cols-update_params=False-step=1-1-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:2cols-update_params=False-step=1-1-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:2cols-update_params=False-step=5-0-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:2cols-update_params=False-step=5-0-fh=[2 5]]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:2cols-update_params=False-step=5-1-fh=1]': 'PASSED',\n 'test_update_predict_predicted_index[CustomNaiveForecaster-1-y:2cols-update_params=False-step=5-1-fh=[2 5]]': 'PASSED',\n 'test_raises_not_fitted_error[CustomNaiveForecaster-0]': 'PASSED',\n 'test_raises_not_fitted_error[CustomNaiveForecaster-1]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=1-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=1-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=1-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=1-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=1-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=1-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=1-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=1-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=1-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=-3-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=-3-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=-3-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=-3-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=-3-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=-3-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=-3-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=-3-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=-3-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-2 -5]-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-2 -5]-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-2 -5]-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-2 -5]-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-2 -5]-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-2 -5]-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-2 -5]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-2 -5]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-2 -5]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=0-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=0-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=0-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=0-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=0-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=0-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=0-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=0-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=0-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-3  2]-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-3  2]-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-3  2]-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-3  2]-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-3  2]-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-3  2]-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-3  2]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-3  2]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:1cols-fh=[-3  2]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=1-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=1-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=1-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=1-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=1-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=1-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=1-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=1-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=1-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=-3-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=-3-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=-3-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=-3-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=-3-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=-3-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=-3-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=-3-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=-3-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-2 -5]-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-2 -5]-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-2 -5]-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-2 -5]-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-2 -5]-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-2 -5]-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-2 -5]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-2 -5]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-2 -5]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=0-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=0-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=0-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=0-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=0-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=0-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=0-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=0-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=0-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-3  2]-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-3  2]-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-3  2]-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-3  2]-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-3  2]-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-3  2]-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-3  2]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-3  2]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-0-y:2cols-fh=[-3  2]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=1-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=1-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=1-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=1-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=1-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=1-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=1-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=1-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=1-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=-3-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=-3-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=-3-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=-3-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=-3-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=-3-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=-3-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=-3-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=-3-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-2 -5]-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-2 -5]-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-2 -5]-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-2 -5]-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-2 -5]-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-2 -5]-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-2 -5]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-2 -5]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-2 -5]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=0-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=0-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=0-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=0-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=0-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=0-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=0-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=0-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=0-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-3  2]-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-3  2]-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-3  2]-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-3  2]-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-3  2]-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-3  2]-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-3  2]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-3  2]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:1cols-fh=[-3  2]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=1-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=1-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=1-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=1-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=1-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=1-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=1-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=1-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=1-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=-3-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=-3-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=-3-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=-3-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=-3-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=-3-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=-3-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=-3-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=-3-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-2 -5]-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-2 -5]-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-2 -5]-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-2 -5]-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-2 -5]-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-2 -5]-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-2 -5]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-2 -5]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-2 -5]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=0-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=0-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=0-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=0-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=0-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=0-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=0-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=0-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=0-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-3  2]-int-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-3  2]-int-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-3  2]-range-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-3  2]-range-int-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-3  2]-period-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-3  2]-period-period-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-3  2]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-3  2]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index[CustomNaiveForecaster-1-y:2cols-fh=[-3  2]-datetime-timedelta-True]': 'PASSED',\n 'test_y_invalid_type_raises_error[CustomNaiveForecaster-0-0]': 'PASSED',\n 'test_y_invalid_type_raises_error[CustomNaiveForecaster-0-1]': 'PASSED',\n 'test_y_invalid_type_raises_error[CustomNaiveForecaster-1-0]': 'PASSED',\n 'test_y_invalid_type_raises_error[CustomNaiveForecaster-1-1]': 'PASSED',\n 'test_categorical_y_raises_error[CustomNaiveForecaster-0]': 'PASSED',\n 'test_categorical_y_raises_error[CustomNaiveForecaster-1]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-0-y:1cols-fh=1-alpha=0.05]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-0-y:1cols-fh=1-alpha=0.1]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-0-y:1cols-fh=1-alpha=[0.25, 0.75]]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-alpha=0.05]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-alpha=0.1]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-alpha=[0.25, 0.75]]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-0-y:2cols-fh=1-alpha=0.05]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-0-y:2cols-fh=1-alpha=0.1]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-0-y:2cols-fh=1-alpha=[0.25, 0.75]]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-alpha=0.05]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-alpha=0.1]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-alpha=[0.25, 0.75]]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-1-y:1cols-fh=1-alpha=0.05]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-1-y:1cols-fh=1-alpha=0.1]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-1-y:1cols-fh=1-alpha=[0.25, 0.75]]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-alpha=0.05]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-alpha=0.1]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-alpha=[0.25, 0.75]]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-1-y:2cols-fh=1-alpha=0.05]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-1-y:2cols-fh=1-alpha=0.1]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-1-y:2cols-fh=1-alpha=[0.25, 0.75]]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-alpha=0.05]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-alpha=0.1]': 'PASSED',\n 'test_predict_quantiles[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-alpha=[0.25, 0.75]]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-0-y:1cols-update_params=True-fh=1]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-0-y:1cols-update_params=True-fh=[2 5]]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-0-y:1cols-update_params=False-fh=1]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-0-y:1cols-update_params=False-fh=[2 5]]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-0-y:2cols-update_params=True-fh=1]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-0-y:2cols-update_params=True-fh=[2 5]]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-0-y:2cols-update_params=False-fh=1]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-0-y:2cols-update_params=False-fh=[2 5]]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-1-y:1cols-update_params=True-fh=1]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-1-y:1cols-update_params=True-fh=[2 5]]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-1-y:1cols-update_params=False-fh=1]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-1-y:1cols-update_params=False-fh=[2 5]]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-1-y:2cols-update_params=True-fh=1]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-1-y:2cols-update_params=True-fh=[2 5]]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-1-y:2cols-update_params=False-fh=1]': 'PASSED',\n 'test_update_predict_single[CustomNaiveForecaster-1-y:2cols-update_params=False-fh=[2 5]]': 'PASSED',\n 'test_update_with_exogenous_variables[CustomNaiveForecaster-0-y:1cols-update_params=True]': 'PASSED',\n 'test_update_with_exogenous_variables[CustomNaiveForecaster-0-y:1cols-update_params=False]': 'PASSED',\n 'test_update_with_exogenous_variables[CustomNaiveForecaster-0-y:2cols-update_params=True]': 'PASSED',\n 'test_update_with_exogenous_variables[CustomNaiveForecaster-0-y:2cols-update_params=False]': 'PASSED',\n 'test_update_with_exogenous_variables[CustomNaiveForecaster-1-y:1cols-update_params=True]': 'PASSED',\n 'test_update_with_exogenous_variables[CustomNaiveForecaster-1-y:1cols-update_params=False]': 'PASSED',\n 'test_update_with_exogenous_variables[CustomNaiveForecaster-1-y:2cols-update_params=True]': 'PASSED',\n 'test_update_with_exogenous_variables[CustomNaiveForecaster-1-y:2cols-update_params=False]': 'PASSED',\n 'test_X_invalid_type_raises_error[CustomNaiveForecaster-0-y:1cols-0]': 'PASSED',\n 'test_X_invalid_type_raises_error[CustomNaiveForecaster-0-y:1cols-1]': 'PASSED',\n 'test_X_invalid_type_raises_error[CustomNaiveForecaster-0-y:2cols-0]': 'PASSED',\n 'test_X_invalid_type_raises_error[CustomNaiveForecaster-0-y:2cols-1]': 'PASSED',\n 'test_X_invalid_type_raises_error[CustomNaiveForecaster-1-y:1cols-0]': 'PASSED',\n 'test_X_invalid_type_raises_error[CustomNaiveForecaster-1-y:1cols-1]': 'PASSED',\n 'test_X_invalid_type_raises_error[CustomNaiveForecaster-1-y:2cols-0]': 'PASSED',\n 'test_X_invalid_type_raises_error[CustomNaiveForecaster-1-y:2cols-1]': 'PASSED',\n 'test_pred_int_tag[CustomNaiveForecaster-0]': 'PASSED',\n 'test_pred_int_tag[CustomNaiveForecaster-1]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:1cols-int-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:1cols-int-int-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:1cols-range-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:1cols-range-int-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:1cols-period-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:1cols-period-period-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:1cols-datetime-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:1cols-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:1cols-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:2cols-int-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:2cols-int-int-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:2cols-range-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:2cols-range-int-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:2cols-period-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:2cols-period-period-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:2cols-datetime-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:2cols-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-0-y:2cols-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:1cols-int-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:1cols-int-int-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:1cols-range-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:1cols-range-int-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:1cols-period-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:1cols-period-period-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:1cols-datetime-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:1cols-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:1cols-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:2cols-int-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:2cols-int-int-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:2cols-range-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:2cols-range-int-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:2cols-period-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:2cols-period-period-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:2cols-datetime-int-True]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:2cols-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index_in_sample_full[CustomNaiveForecaster-1-y:2cols-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=1-int-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=1-int-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=1-range-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=1-range-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=1-period-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=1-period-period-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=1-datetime-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=1-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=1-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-int-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-int-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-range-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-range-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-period-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-period-period-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:1cols-fh=[2 5]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=1-int-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=1-int-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=1-range-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=1-range-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=1-period-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=1-period-period-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=1-datetime-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=1-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=1-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-int-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-int-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-range-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-range-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-period-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-period-period-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-0-y:2cols-fh=[2 5]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=1-int-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=1-int-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=1-range-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=1-range-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=1-period-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=1-period-period-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=1-datetime-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=1-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=1-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-int-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-int-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-range-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-range-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-period-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-period-period-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:1cols-fh=[2 5]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=1-int-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=1-int-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=1-range-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=1-range-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=1-period-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=1-period-period-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=1-datetime-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=1-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=1-datetime-timedelta-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-int-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-int-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-range-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-range-int-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-period-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-period-period-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-datetime-int-True]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-datetime-datetime-False]': 'PASSED',\n 'test_predict_time_index_with_X[CustomNaiveForecaster-1-y:2cols-fh=[2 5]-datetime-timedelta-True]': 'PASSED',\n 'test_predict_series_name_preserved[CustomNaiveForecaster-0]': 'PASSED',\n 'test_predict_series_name_preserved[CustomNaiveForecaster-1]': 'PASSED',\n 'test_fh_attribute[CustomNaiveForecaster-0-y:1cols]': 'PASSED',\n 'test_fh_attribute[CustomNaiveForecaster-0-y:2cols]': 'PASSED',\n 'test_fh_attribute[CustomNaiveForecaster-1-y:1cols]': 'PASSED',\n 'test_fh_attribute[CustomNaiveForecaster-1-y:2cols]': 'PASSED',\n 'test_hierarchical_with_exogeneous[CustomNaiveForecaster-0-y:1cols]': 'PASSED',\n 'test_hierarchical_with_exogeneous[CustomNaiveForecaster-0-y:2cols]': 'PASSED',\n 'test_hierarchical_with_exogeneous[CustomNaiveForecaster-1-y:1cols]': 'PASSED',\n 'test_hierarchical_with_exogeneous[CustomNaiveForecaster-1-y:2cols]': 'PASSED',\n 'test_score[CustomNaiveForecaster-0-y:1cols-fh=1]': 'PASSED',\n 'test_score[CustomNaiveForecaster-0-y:1cols-fh=[2 5]]': 'PASSED',\n 'test_score[CustomNaiveForecaster-0-y:2cols-fh=1]': 'PASSED',\n 'test_score[CustomNaiveForecaster-0-y:2cols-fh=[2 5]]': 'PASSED',\n 'test_score[CustomNaiveForecaster-1-y:1cols-fh=1]': 'PASSED',\n 'test_score[CustomNaiveForecaster-1-y:1cols-fh=[2 5]]': 'PASSED',\n 'test_score[CustomNaiveForecaster-1-y:2cols-fh=1]': 'PASSED',\n 'test_score[CustomNaiveForecaster-1-y:2cols-fh=[2 5]]': 'PASSED',\n 'test_predict_proba[CustomNaiveForecaster-0-y:1cols-fh=1]': 'PASSED',\n 'test_predict_proba[CustomNaiveForecaster-0-y:1cols-fh=[2 5]]': 'PASSED',\n 'test_predict_proba[CustomNaiveForecaster-0-y:2cols-fh=1]': 'PASSED',\n 'test_predict_proba[CustomNaiveForecaster-0-y:2cols-fh=[2 5]]': 'PASSED',\n 'test_predict_proba[CustomNaiveForecaster-1-y:1cols-fh=1]': 'PASSED',\n 'test_predict_proba[CustomNaiveForecaster-1-y:1cols-fh=[2 5]]': 'PASSED',\n 'test_predict_proba[CustomNaiveForecaster-1-y:2cols-fh=1]': 'PASSED',\n 'test_predict_proba[CustomNaiveForecaster-1-y:2cols-fh=[2 5]]': 'PASSED',\n 'test_y_multivariate_raises_error[CustomNaiveForecaster-0]': 'PASSED',\n 'test_y_multivariate_raises_error[CustomNaiveForecaster-1]': 'PASSED',\n 'test_categorical_X_raises_error[CustomNaiveForecaster-0]': 'PASSED',\n 'test_categorical_X_raises_error[CustomNaiveForecaster-1]': 'PASSED',\n 'test_fit_predict[CustomNaiveForecaster-0-y:1cols]': 'PASSED',\n 'test_fit_predict[CustomNaiveForecaster-0-y:2cols]': 'PASSED',\n 'test_fit_predict[CustomNaiveForecaster-1-y:1cols]': 'PASSED',\n 'test_fit_predict[CustomNaiveForecaster-1-y:2cols]': 'PASSED'}",
    "crumbs": [
      "Part III: Apêndices",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Criando modelos customizados com sktime</span>"
    ]
  }
]