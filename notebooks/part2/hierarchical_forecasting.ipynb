{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Forecasting Hierárquico\n",
        "\n",
        "Muitas vezes, não apenas temos múltiplas séries temporais, mas essas séries também estão organizadas em uma hierarquia. Por exemplo, vendas de produtos podem ser organizadas por SKU, categoria, departamento e total da loja.\n",
        "\n",
        "Vamos usar o mesmo dataset sintético, mas agora com uma hierarquia de produtos.\n",
        "\n",
        "```{mermaid}\n",
        "\n",
        "graph TD\n",
        "  root[\"__total\"]\n",
        "\n",
        "  %% group -1\n",
        "  root --> g_minus1[\"-1\"]\n",
        "  g_minus1 --> sku20[\"20\"]\n",
        "  g_minus1 --> sku21[\"21\"]\n",
        "  g_minus1 --> sku22[\"22\"]\n",
        "  g_minus1 --> sku23[\"23\"]\n",
        "  g_minus1 --> sku24[\"24\"]\n",
        "\n",
        "  %% group 0\n",
        "  root --> g0[\"0\"]\n",
        "  g0 --> sku0[\"0\"]\n",
        "  g0 --> sku1[\"1\"]\n",
        "  g0 --> sku2[\"2\"]\n",
        "  g0 --> sku3[\"3\"]\n",
        "  g0 --> sku4[\"4\"]\n",
        "\n",
        "  %% group 1\n",
        "  root --> g1[\"...\"]\n",
        "\n",
        "  \n",
        "  %% group 3\n",
        "  root --> g3[\"3\"]\n",
        "  g3 --> sku15[\"15\"]\n",
        "  g3 --> sku16[\"16\"]\n",
        "  g3 --> sku17[\"17\"]\n",
        "  g3 --> sku18[\"18\"]\n",
        "  g3 --> sku19[\"19\"]\n",
        "```\n",
        "\n",
        "\n",
        "Ao mesmo tempo que dados hierarárquicos são interessantes pois nos trazem mais informação, eles também trazem desafios adicionais. Imagine que queremos prever as vendas futuras de cada produto. Se fizermos previsões independetes para cada produto, não há garantia que a soma das previsões dos produtos será igual à previsão do total da loja. Isso é chamado de incoerência nas previsões hierárquicas. O processo de ajustar as previsões para garantir coerência é chamado de **reconciliação**.\n",
        "\n",
        "## Carregando dados\n",
        "\n",
        "Vamos usar os dados sintéticos, agora com sua versao hierárquica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: false\n",
        "\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from tsbook.datasets.retail import SyntheticRetail\n",
        "\n",
        "dataset = SyntheticRetail(\"hierarchical\")\n",
        "y_train, X_train, y_test, X_test = dataset.load(\"y_train\", \"X_train\", \"y_test\", \"X_test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Uso de pandas e dados hierárquicos\n",
        "\n",
        "Agora, os dataframes possuem mais de 2 ou mais índices, representando a hierarquia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para obter o número de pontos de série únicos (séries temporais individuais), podemos fazer o seguinte:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_train.index.droplevel(-1).nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note que existem algumas séries com um identificador `__total`. Esse identificador representa o total para aquele nível da hierarquia. Por exemplo, se o id completo é `(-1, \"__total\")`, isso representa o total do grupo -1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_train.loc[(-1, \"__total\")].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O total de todas as séries é representado por `(\"__total\", \"__total\")`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_train.loc[(\"__total\", \"__total\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para contabilizar o número de séries temporais individuais, podemos fazer o seguinte:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_train.index.droplevel(-1).nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Previsão sem reconciliação\n",
        "\n",
        "Vamos fazer uma previsão e entender o problema da incoerência."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fh = y_test.index.get_level_values(-1).unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from tsbook.forecasting.reduction import ReductionForecaster\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "forecaster = ReductionForecaster(\n",
        "    LGBMRegressor(n_estimators=50, verbose=-1, objective=\"tweedie\"),\n",
        "    window_length=30,\n",
        "    normalization_strategy=\"divide_mean\",\n",
        ")\n",
        "forecaster.fit(y_train, X=X_train)\n",
        "y_pred = forecaster.predict(fh, X=X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para somar as previsões de baixo para cima, podemos usar o transformador `Aggregator`. Vamos ver que,\n",
        "quando somarmos as previsões das séries filhas, o resultado não é igual à previsão da série total."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime.transformations.hierarchical.aggregate import Aggregator\n",
        "\n",
        "Aggregator().fit_transform(y_pred) - y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Existe uma diferença... ou seja, os valores não batem.\n",
        "Imagine o impacto de levar previsões incoerentes para a tomada de decisão em uma empresa?\n",
        "A raiz do problema é que temos mais modelos que graus de liberdade. Para ilustrar, suponha que temos 3 séries: $A$, $B$ e $C$, onde:\n",
        "\n",
        "$$\n",
        "C(t) = A(t) + B(t)\n",
        "$$\n",
        "\n",
        "Aqui, temos 3 séries, mas apenas 2 graus de liberdade, pois $C$ é completamente determinado por $A$ e $B$. Se fizermos previsões independentes para $A$, $B$ e $C$, não há garantia de que a relação acima será mantida nas previsões.\n",
        "\n",
        "## Reconciliação de previsões hierárquicas\n",
        "\n",
        "![](img/hierarchical_reconciled_vs_not.png)\n",
        "\n",
        "Existem diferentes métodos para reconciliar previsões em séries temporais hierárquicas. Não existe uma solução única, e o melhor método depende dos dados e do contexto.\n",
        "\n",
        "## Bottom-up\n",
        "\n",
        "A maneira mais simples de reconcialiar previsões hierárquicas é a abordagem **bottom-up**. Nessa abordagem, fazemos previsões apenas para as séries mais baixas na hierarquia (as séries filhas) e depois somamos essas previsões para obter as previsões das séries superiores (as séries pais).\n",
        "\n",
        "<img src=\"img/hierarchical_bottomup.png\" alt=\"Hierarchical Bottom-up\" width=\"450\">\n",
        "\n",
        "Lados positivos:\n",
        "\n",
        "* Simplicidade: fácil de entender e implementar.\n",
        "* Coerência garantida: a soma das previsões das séries filhas sempre será igual à previsão da série pai.\n",
        "* Sérias filhas podem capturar detalhes específicos que podem ser perdidos em níveis superiores.\n",
        "\n",
        "No entanto, essa abordagem também tem desvantagens: é sucetível ao ruído nas séries filhas, e se as séries filhas tiverem pouca informação, as previsões podem ser ruins. Por exemplo, muitos zeros nas séries de níveis baixos pode levar a previsões ruins a niveis agregados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime.transformations.hierarchical.reconcile import BottomUpReconciler\n",
        "\n",
        "bottom_up = BottomUpReconciler() * forecaster\n",
        "bottom_up.fit(y_train)\n",
        "\n",
        "y_pred_bottomup = bottom_up.predict(fh=fh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora vemos que as previsões são coerentes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Aggregator().fit_transform(y_pred_bottomup) - y_pred_bottomup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Top-down (forecast proportions)\n",
        "\n",
        "Outra abordagem é a **top-down**. Nessa abordagem, fazemos previsões apenas para as séries superiores na hierarquia (as séries pais) e depois distribuímos essas previsões para as séries filhas com base em proporções previstas.\n",
        "\n",
        "Suponha que temos a seguinte hierarquia $C(t) = A(t) + B(t)$. Considere $\\hat{C}(t)$, $\\hat{A}(t)$ e $\\hat{B}(t)$ como as previsões para $C$, $A$ e $B$, respectivamente. Na abordagem top-down, faríamos o seguinte:\n",
        "\n",
        "1. Prever $\\hat{C}(t)$, $\\hat{A}(t)$ e $\\hat{B}(t)$ independentemente.\n",
        "2. Calcular as proporções previstas para os níveis mais baixos:\n",
        "$$\n",
        "p_A(t) = \\frac{\\hat{A}(t)}{\\hat{A}(t) + \\hat{B}(t)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "p_B(t) = \\frac{\\hat{B}(t)}{\\hat{A}(t) + \\hat{B}(t)}\n",
        "$$\n",
        "\n",
        "3. Distribuir a previsão de $C$ para $A$ e $B$ usando essas proporções:\n",
        "$$\n",
        "\\tilde{A}(t) = p_A(t) \\cdot \\hat{C}(t)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\tilde{B}(t) = p_B(t) \\cdot \\hat{C}(t)\n",
        "$$\n",
        "\n",
        "Essa abordagem é capaz de usufruir da qualidade do forecast total, e ainda consegue distribuir para as séries filhas baseadas no histórico.\n",
        "\n",
        "<img src=\"img/hierarchical_td_fcst.png\" alt=\"Topdown Forecast\" width=\"900\">\n",
        "\n",
        "\n",
        "O que chamam de \"Proporções históricas\" é equivalente a esse método, mas com um modelo Naive para prever as proporções.\n",
        "\n",
        "Esse método pode ser bom quando o forecast total é de boa qualidade. No entanto,\n",
        "dependemos profundamente da qualidade do forecast total e das proporções."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime.transformations.hierarchical.reconcile import TopdownReconciler\n",
        "\n",
        "top_down_fcst = TopdownReconciler() * forecaster\n",
        "top_down_fcst.fit(y_train)\n",
        "\n",
        "y_pred_topdown = top_down_fcst.predict(fh=fh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reconciliação ótima\n",
        "\n",
        "Existe uma abordagem mais sofisticada, com uma intuição geométrica interessante.\n",
        "A ideia é ajustar as previsões iniciais para que elas satisfaçam as restrições de soma da hierarquia. Por exemplo, para a hierarquia $C(t) = A(t) + B(t)$, queremos garantir que:\n",
        "\n",
        "$$\n",
        "\\hat{C}(t) = \\hat{A}(t) + \\hat{B}(t)\n",
        "$$\n",
        "\n",
        "Se consideramos nosso espaço 3D de observações $(\\hat{A}, \\hat{B}, \\hat{C})$, a \n",
        "condição acima é satisfeita para um plano 2D nesse universo.\n",
        "\n",
        "\n",
        "![](img/coherent_plane.png)\n",
        "\n",
        "\n",
        "Podemos então projetar nossas previsões iniciais nesse plano para obter previsões coerentes. Essa projeção pode ser feita de várias maneiras, levando a diferentes métodos de reconciliação ótima. Os métodos levam o nome \"OLS\" pois a projeção é feita minimizando o erro quadrático (Ordinary Least Squares).\n",
        "\n",
        "* **OLS** : projetar ortogonalmente todas as previsões base na espaço de reconciliação, tratando todas as séries igualmente.\n",
        "* **Weighted OLS**: projetar obliquamente, ou seja, considerando pesos diferentes para cada série, permitindo dar mais importância a certas séries na reconciliação. A projeção não faz mais uma perpendicular, mas sim uma oblíqua.\n",
        "* **Minimum trace (MinT)**: use a matriz de covariância do erro para encontrar as previsões reconciliadas ótimas. Chamado de \"ótimo\".\n",
        "\n",
        "\n",
        "Para a reconciliação ótima com OLS, podemos usar o `OptimalReconciler` do sktime:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime.transformations.hierarchical.reconcile import OptimalReconciler\n",
        "\n",
        "optimal = OptimalReconciler(\"ols\") * forecaster\n",
        "optimal.fit(y_train)\n",
        "y_pred_optimal = optimal.predict(fh=fh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | code-fold: true\n",
        "from sktime.utils.plotting import plot_series\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "idx = y_train.index.droplevel(-1).unique()[10]\n",
        "\n",
        "plot_series(\n",
        "    y_train.loc[idx,],\n",
        "    y_test.loc[idx,],\n",
        "    y_pred.loc[idx,],\n",
        "    y_pred_optimal.loc[idx,],\n",
        "    labels=[\"Train\", \"Test\", \"Predicted (sem reconciliação)\", \"Predicted (ótimo)\"],\n",
        ")\n",
        "plt.xlim(pd.to_datetime(\"2024-05-01\"), None)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para reconciliações ótimas (que usam a covariância do erro), podemos usar o `ReconcilerForecaster` do sktime, que internamente já faz o cálculo da covariância do erro:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime.forecasting.reconcile import ReconcilerForecaster\n",
        "\n",
        "\n",
        "mint_forecaster = ReconcilerForecaster(\n",
        "    forecaster=forecaster,\n",
        "    method=\"mint_shrink\")\n",
        "\n",
        "mint_forecaster.fit(y_train)\n",
        "y_pred_mint = mint_forecaster.predict(fh=fh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparando resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime.performance_metrics.forecasting import MeanSquaredScaledError\n",
        "\n",
        "metric = MeanSquaredScaledError(multilevel=\"uniform_average_time\")\n",
        "\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        \"Baseline\": metric(y_test, y_pred, y_train=y_train),\n",
        "        \"BottomUpReconciler\": metric(y_test, y_pred_bottomup, y_train=y_train),\n",
        "        \"TopDownReconciler\": metric(y_test, y_pred_topdown, y_train=y_train),\n",
        "        \"OptimalReconciler (ols)\": metric(y_test, y_pred_optimal, y_train=y_train),\n",
        "        \"Mint Reconciler\": metric(y_test, y_pred_mint, y_train=y_train),\n",
        "    },\n",
        "    index=[\"Mean Absolute Scaled Error\"],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/felipeangelim/Workspace/python_brasil_2025/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}