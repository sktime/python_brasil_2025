{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dados em painel (multi-series)\n",
        "\n",
        "Em muitas aplicações, não temos acesso a uma única série temporal, mas sim a um conjunto de séries temporais relacionadas. Isso é comum em cenários como vendas de produtos em diferentes lojas, consumo de energia em diferentes regiões, etc. Esses dados são chamados de dados em painel.\n",
        "\n",
        "Uma ideia poderosa é aproveitar a similaridade entre as séries para melhorar as previsões. Chamamos de **modelos globais** os modelos capazes de aprender padrões comuns entre as séries, ao contrário dos **modelos locais** que aprendem apenas com uma única série.\n",
        "\n",
        "A maioria dos modelos clássicos de séries temporais são locais. Modelos globais são, em geral, baseados em modelos tabulares de ML ou deep learning. Segundo competições de séries temporais, como a M5, em forecasts de painel os modelos globais são os que apresentam melhor desempenho [@makridakis2022m5].\n",
        "\n",
        "\n",
        "## Acessando os dados\n",
        "\n",
        "Aqui, vamos usar o dataset sintético que vimos antes, mas agora teremos acesso às várias séries temporais que compõe o total.\n",
        "\n",
        "Esse dataset é feito para simular um caso de varejo, onde temos vendas diárias de vários produtos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: false\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | code-fold: true\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sktime.utils.plotting import plot_series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from tsbook.datasets.retail import SyntheticRetail\n",
        "dataset = SyntheticRetail(\"panel\")\n",
        "y_train, X_train, y_test, X_test = dataset.load(\n",
        "    \"y_train\", \"X_train\", \"y_test\", \"X_test\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note que, para dados em painel, os dataframes possuem mais um nível de índice, que identifica a série temporal a que cada observação pertence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "display(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos visualizar algumas séries. Vemos que há mais zeros nesse dataset, em comparação\n",
        "ao que usamos antes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime.utils.plotting import plot_series\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "y_train.unstack(level=0).droplevel(0, axis=1).iloc[:, [0,10]].plot(ax=ax, alpha=0.7)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pandas e multi-índices\n",
        "\n",
        "Para trabalhar com essas estruturas de dados, é importante revisar algumas operações do pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_train.index.get_level_values(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As seguintes operações são bem úteis para trabalhar com multi-índices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_train.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Acessar valores únicos no primeiro nivel (nível 0, mais à esquerda):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_train.index.get_level_values(0).unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Selecionar uma série específica (nível 0 igual a 0):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_train.loc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aqui, podemos usar `pd.IndexSlice` para selecionar várias séries ao mesmo tempo.\n",
        "Note que pd.IndexSlice é passado diretamente para `.loc`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_train.loc[pd.IndexSlice[[0,2], :]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora, para selecionar o horizonte de forecasting, temos que chamar `unique`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fh = y_test.index.get_level_values(1).unique()\n",
        "\n",
        "fh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upcasting automático\n",
        "\n",
        "Nem todos modelos suportam nativamente dados em painel. Por exemplo, exponential smoothing.\n",
        "Aqui, temos uma boa notícia: sem linhas extras necessárias. O sktime faz *upcasting* automático para dados em painel ao usar estimadores do `sktime`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime.forecasting.naive import NaiveForecaster\n",
        "\n",
        "\n",
        "naive_forecaster = NaiveForecaster(strategy=\"last\", window_length=1)\n",
        "naive_forecaster.fit(y_train)\n",
        "y_pred_naive = naive_forecaster.predict(fh=fh)\n",
        "\n",
        "y_pred_naive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Internamente, o `sktime` cria um clone do estimador para cada série nos dados em painel.\n",
        "Em seguida, cada clone é treinado com a série correspondente. Isso é feito de\n",
        "forma transparente para usuário, mas sem exigir esforço.\n",
        "\n",
        "O atributo `forecasters_` armazena um DataFrame com os estimatores de cada série."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "naive_forecaster.forecasters_.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "É dificil explicar o quanto isso é extremamente útil para código limpo e prototipagem rápida.\n",
        "Foi um dos motivos que me levaram a usar o `sktime`.\n",
        "\n",
        "\n",
        "## Métricas\n",
        "\n",
        "Agora que temos várias séries, precisamos explicar como calcular métricas de avaliação.\n",
        "O sktime oferece duas opções para isso, como argumentos na criação da métrica:\n",
        "\n",
        "* `multilevel=\"uniform_average_time\"` para calcular a média das séries temporais no painel.\n",
        "* `multilevel=\"raw_values\"` para obter o erro por série.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime.performance_metrics.forecasting import MeanSquaredScaledError\n",
        "\n",
        "metric = MeanSquaredScaledError(multilevel=\"uniform_average_time\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "metric(y_true=y_test, y_pred=y_pred_naive, y_train=y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Na prática, as métricas que a sua aplicação exige podem ser diferentes. Por exemplo,\n",
        "as séries temporais podem ter diferentes importâncias, e você pode querer ponderar\n",
        "as métricas de acordo. \n",
        "\n",
        "Para isso, é possível criar uma métrica customizada no sktime, mas não entraremos\n",
        "nesse mérito aqui.\n",
        "\n",
        "## Modelos globais de Machine Learning\n",
        "\n",
        "Quando vimos como usar modelos de Machine Learning para forecasting, já mencionamos\n",
        "como é necessário traduzir o problema de séries temporais para um problema de regressão tradicional.\n",
        "\n",
        "No caso de dados em painel, também podemos usar essa abordagem, mas agora aproveitando\n",
        "todas as séries temporais para treinar um único modelo global.\n",
        " \n",
        "![](img/global_reduction.png)\n",
        "\n",
        "Abaixo, vamos comparar um LightGBM global com um local. Veremos o seguinte: o modelo local é **melhor** que o modelo global, **se não processarmos os dados** corretamente para o modelo global aproveitar as **similaridades** entre as séries!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from tsbook.forecasting.reduction import ReductionForecaster\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "global_forecaster1 = ReductionForecaster(\n",
        "    LGBMRegressor(n_estimators=100, verbose=-1),\n",
        "    window_length=30,\n",
        ")\n",
        "\n",
        "global_forecaster1.fit(y_train, X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_pred_global1 = global_forecaster1.predict(fh=fh, X=X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "y_train.loc[10, \"sales\"].plot(ax=ax, label=\"Treino\")\n",
        "y_test.loc[10, \"sales\"].plot(ax=ax, label=\"Teste\")\n",
        "y_pred_global1.loc[10, \"sales\"].plot(ax=ax, label=\"Global 1\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para forçar que um modelo global funcione como um modelo local, podemos usar `ForecastByLevel`, que cria um modelo separado para cada série temporal, mesmo quando o estimador suporta dados em painel.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime.forecasting.compose import ForecastByLevel\n",
        "\n",
        "local_forecaster1 = ForecastByLevel(global_forecaster1, groupby=\"local\")\n",
        "\n",
        "local_forecaster1.fit(y_train, X=X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_pred_local1 = local_forecaster1.predict(fh=fh, X=X_test)\n",
        "\n",
        "err_global1 = metric(y_true=y_test, y_pred=y_pred_global1, y_train=y_train)\n",
        "err_local1 = metric(y_true=y_test, y_pred=y_pred_local1, y_train=y_train)\n",
        "\n",
        "errors = pd.DataFrame(\n",
        "    {\n",
        "        \"Global (1)\": [err_global1],\n",
        "        \"Local (1)\": [err_local1],\n",
        "    },\n",
        "    index=[\"MSE\"],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessamento e engenharia de features\n",
        "\n",
        "Sabemos como preprocessar séries temporais univariadas para melhorar o desempenho dos modelos de ML. Aplicamos da mesma maneira que fizemos anteriormente o `Differencer`, com objetivo de remover tendências."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime.transformations.series.difference import Differencer\n",
        "\n",
        "\n",
        "global_forecaster2 = Differencer() * global_forecaster1\n",
        "global_forecaster2.fit(y_train, X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_pred_global2 = global_forecaster2.predict(fh=fh, X=X_test)\n",
        "metric_global2 = metric(y_true=y_test, y_pred=y_pred_global2, y_train=y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E agora sua versão local:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "local_forecaster2 = ForecastByLevel(global_forecaster2, groupby=\"local\")\n",
        "local_forecaster2.fit(y_train, X=X_train)\n",
        "\n",
        "y_pred_local2 = local_forecaster2.predict(fh=fh, X=X_test)\n",
        "metric_local2 = metric(y_true=y_test, y_pred=y_pred_local2, y_train=y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora, podemos comparar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "errors[\"Global (2)\"] = metric_global2\n",
        "errors[\"Local (2)\"] = metric_local2\n",
        "\n",
        "errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note como já superamos o modelo global incial, e o modelo local. Isso é para\n",
        "destacar que é **essencial** realizar um bom preprocessamento e engenharia de features para que modelos de Machine Learning tenham bom desempenho em dados em painel.\n",
        "\n",
        "### Normalização por janela\n",
        "\n",
        "Agora, vamos usar a normalização por janela, que é especialmente útil em dados em painel, onde as séries podem ter diferentes escalas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "global_forecaster3 = global_forecaster1.clone().set_params(\n",
        "    normalization_strategy=\"divide_mean\"\n",
        ")\n",
        "\n",
        "global_forecaster3.fit(y_train, X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Predict\n",
        "y_pred_global3 = global_forecaster3.predict(fh=fh, X=X_test)\n",
        "\n",
        "# Métrica\n",
        "metric_global3 = metric(y_true=y_test, y_pred=y_pred_global3, y_train=y_train)\n",
        "\n",
        "errors[\"Global 3 (window norm)\"] = metric_global3\n",
        "\n",
        "display(errors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que resultados são ainda melhores!\n",
        "\n",
        "\n",
        "### Pipelines de features exógenas\n",
        "\n",
        "Podemos ajudar o modelo a capturar sazonalidades adicionando features de Fourier como features exógenas.\n",
        "\n",
        "Usamos `**` para criar um pipeline aplicado sobre as features exógenas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime.transformations.series.fourier import FourierFeatures\n",
        "\n",
        "fourier_features = FourierFeatures(\n",
        "    sp_list=[365.25, 365.25 / 12], fourier_terms_list=[1, 1], freq=\"D\"\n",
        ")\n",
        "\n",
        "global_forecaster4 = fourier_features**global_forecaster3\n",
        "global_forecaster4.fit(y_train, X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_pred_global4 = global_forecaster4.predict(fh=fh, X=X_test)\n",
        "metric_global4 = metric(y_true=y_test, y_pred=y_pred_global4, y_train=y_train)\n",
        "\n",
        "errors[\"Global 4 (fourier)\"] = metric_global4\n",
        "errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agrupamento + Modelos globais\n",
        "\n",
        "Uma técnica muito adotada é fazer modelos globais por clusters de séries temporais similares. \n",
        "\n",
        "Uma maneira de categorizar é usando ADI (Average Demand Interval) e CV² (squared Coefficient of Variation). O componente ADI é calculado como o percentual de períodos com demanda (y>0), e $CV^2$ é o quadrado do coeficiente de variação das demandas positivas.\n",
        "\n",
        "| **Categoria** | **ADI** | **CV²** | **Padrão típico** | **Exemplos** |\n",
        "|:--------------|:--------|:--------|:------------------|:-------------|\n",
        "| **Suave (Smooth)** | ≤ 1,32 | ≤ 0,49 | Demanda contínua e estável | Itens de consumo diário, alimentos |\n",
        "| **Errática (Erratic)** | ≤ 1,32 | > 0,49 | Demanda contínua, porém muito variável | Moda, eletrônicos |\n",
        "| **Intermitente (Intermittent)** | > 1,32 | ≤ 0,49 | Muitos períodos sem venda, mas valores estáveis quando ocorre | Peças de reposição, ferramentas |\n",
        "| **Irregular (Lumpy)** | > 1,32 | > 0,49 | Muitos períodos com zero e valores muito variáveis quando há demanda | Equipamentos caros, sobressalentes grandes |\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: false\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "\n",
        "def compute_adi(y):\n",
        "    nnz = np.count_nonzero(y > 0)\n",
        "    return len(y) / nnz if nnz > 0 else np.inf\n",
        "\n",
        "\n",
        "def compute_cv2(y):\n",
        "    pos = y[y > 0]\n",
        "    if len(pos) <= 1:\n",
        "        return np.inf\n",
        "    m = pos.mean()\n",
        "    s = pos.std(ddof=1)\n",
        "    return (s / m) ** 2 if m > 0 else np.inf\n",
        "\n",
        "\n",
        "def plot_category(ax, series_list, title):\n",
        "    x = np.arange(len(series_list[0]))\n",
        "    for y in series_list:\n",
        "        ax.plot(x, y, linewidth=2)\n",
        "    adis = [compute_adi(y) for y in series_list]\n",
        "    cv2s = [compute_cv2(y) for y in series_list]\n",
        "    ax.text(\n",
        "        0.02,\n",
        "        0.98,\n",
        "        f\"avg ADI={np.mean(adis):.2f}\\navg CV²={np.mean(cv2s):.2f}\",\n",
        "        transform=ax.transAxes,\n",
        "        va=\"top\",\n",
        "        ha=\"left\",\n",
        "        bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"0.5\", alpha=0.9),\n",
        "    )\n",
        "    ax.set_title(title, fontsize=12)\n",
        "    ax.set_xlabel(\"time\")\n",
        "    ax.set_ylabel(\"demand\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "\n",
        "N = 60\n",
        "\n",
        "\n",
        "def gen_smooth(n=3):\n",
        "    out = []\n",
        "    for _ in range(n):\n",
        "        base = 20 + 2 * np.sin(np.linspace(0, 3 * np.pi, N))\n",
        "        noise = rng.normal(0, 2, N)\n",
        "        out.append(np.clip(base + noise, 0, None))\n",
        "    return out\n",
        "\n",
        "\n",
        "def gen_erratic(n=3):\n",
        "    out = []\n",
        "    for _ in range(n):\n",
        "        base = 20 + 2 * np.sin(np.linspace(0, 2 * np.pi, N))\n",
        "        noise = rng.normal(0, 9, N)\n",
        "        out.append(np.clip(base + noise, 0, None))\n",
        "    return out\n",
        "\n",
        "\n",
        "def gen_intermittent(n=3):\n",
        "    out = []\n",
        "    for _ in range(n):\n",
        "        mask = rng.binomial(1, 0.35, N)\n",
        "        values = 18 + rng.normal(0, 2, N)\n",
        "        out.append(np.clip(mask * values, 0, None))\n",
        "    return out\n",
        "\n",
        "\n",
        "def gen_lumpy(n=3):\n",
        "    out = []\n",
        "    for _ in range(n):\n",
        "        mask = rng.binomial(1, 0.25, N)\n",
        "        values = rng.gamma(shape=2.0, scale=10.0, size=N)\n",
        "        out.append(np.clip(mask * values, 0, None))\n",
        "    return out\n",
        "\n",
        "\n",
        "cats = [\n",
        "    (\"Smooth (low ADI, low CV²)\", gen_smooth()),\n",
        "    (\"Erratic (low ADI, high CV²)\", gen_erratic()),\n",
        "    (\"Intermittent (high ADI, low CV²)\", gen_intermittent()),\n",
        "    (\"Lumpy (high ADI, high CV²)\", gen_lumpy()),\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
        "for ax, (title, series) in zip(axes.ravel(), cats):\n",
        "    plot_category(ax, series, title)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime.forecasting.compose import GroupbyCategoryForecaster\n",
        "from sktime.transformations.series.adi_cv import ADICVTransformer\n",
        "\n",
        "# TODO: customize yours!\n",
        "group_forecaster = GroupbyCategoryForecaster(\n",
        "    forecasters =\n",
        "        {\"smooth\": global_forecaster3.clone(),\n",
        "        \"erratic\": global_forecaster3.clone(),\n",
        "        \"intermittent\": global_forecaster3.clone(),\n",
        "        \"lumpy\": global_forecaster3.clone(),\n",
        "        },\n",
        "    transformer=ADICVTransformer(features=[\"class\"],))\n",
        "\n",
        "\n",
        "group_forecaster.fit(y_train, X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_pred_group = group_forecaster.predict(fh=fh, X=X_test)\n",
        "metric_group = metric(y_true=y_test, y_pred=y_pred_group, y_train=y_train)\n",
        "\n",
        "metric_group"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Although it did not perform better than the best global model in this synthetic example, in real-world scenarios this approach can be very effective, particularly when there are large samples for each category, allowing the model to learn specific patterns for each group of series.\n",
        "\n",
        "In addition, this can be useful when there are computation constraints, as training multiple smaller models for each cluster can be more efficient than training a single large global model.\n",
        "\n",
        "\n",
        "## Resumo\n",
        "\n",
        "Aqui, vimos como trabalhar com dados em painel (multi-series) usando o sktime. Vimos, especialmente, como criar modelos globais de Machine Learning que aproveitam as similaridades entre as séries para melhorar o desempenho das previsões. Também destacamos a importância do preprocessamento e da engenharia de features para obter bons resultados com esses modelos.\n",
        "\n",
        "Para uma análise mais aprofundada, recomendo o artigo de [@montero2021principles], que discute princípios para forecasting em dados em painel usando modelos globais de Machine Learning.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/felipeangelim/Workspace/python_brasil_2025/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}